{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aW5iW6Jqwi6R",
        "outputId": "a541e1c9-bbd0-4e60-ec92-9b87b12349c9"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"yolo_licenseplate.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1GUjd24TTc85Ol2BsMT3TlxoATde7Qef8\n",
        "\"\"\"\n",
        "\n",
        "!pip install ultralytics kaggle opencv-python matplotlib\n",
        "!pip install roboflow\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files, drive\n",
        "import json\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "\n",
        "print(\"All dependencies installed successfully!\")\n",
        "\n",
        "# CELL 2 - Setup paths and mount Drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Use local paths for faster processing during training\n",
        "local_dataset_path = '/content/Bangla_License_Plate_Dataset'\n",
        "yolo_dataset_path = '/content/yolo_dataset'  # Local for speed\n",
        "drive_backup_path = '/content/drive/MyDrive/Bangla_License_Plate_Dataset'\n",
        "\n",
        "print(\"Drive mounted successfully!\")\n",
        "print(f\"Local dataset path: {local_dataset_path}\")\n",
        "print(f\"YOLO dataset path: {yolo_dataset_path}\")\n",
        "\n",
        "# CELL 3 - Download and prepare dataset\n",
        "# Check if dataset exists locally first, then Drive, then download\n",
        "dataset_ready = False\n",
        "\n",
        "if os.path.exists(local_dataset_path):\n",
        "    print(\"Dataset already exists locally\")\n",
        "    dataset_ready = True\n",
        "elif os.path.exists(drive_backup_path):\n",
        "    print(\"Copying dataset from Drive to local storage...\")\n",
        "    shutil.copytree(drive_backup_path, local_dataset_path)\n",
        "    print(\"Dataset copied to local storage\")\n",
        "    dataset_ready = True\n",
        "else:\n",
        "    print(\"Dataset not found. Please upload your kaggle.json file:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Setup Kaggle API\n",
        "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "    shutil.move('kaggle.json', '/root/.kaggle/kaggle.json')\n",
        "    os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
        "\n",
        "    print(\"Downloading dataset from Kaggle...\")\n",
        "    os.system('kaggle datasets download -d nishat99/bangla-license-plate-detection -p /content')\n",
        "    os.system('unzip -q /content/bangla-license-plate-detection.zip -d /content')\n",
        "\n",
        "    # Move to standard location\n",
        "    if os.path.exists('/content/Bangla License Plate Dataset'):\n",
        "        shutil.move('/content/Bangla License Plate Dataset', local_dataset_path)\n",
        "        dataset_ready = True\n",
        "\n",
        "        # Backup to Drive for future use\n",
        "        try:\n",
        "            shutil.copytree(local_dataset_path, drive_backup_path)\n",
        "            print(\"Dataset backed up to Drive\")\n",
        "        except:\n",
        "            print(\"Drive backup failed, continuing with local dataset\")\n",
        "\n",
        "if not dataset_ready:\n",
        "    print(\"ERROR: Dataset preparation failed!\")\n",
        "else:\n",
        "    print(f\"Dataset ready at: {local_dataset_path}\")\n",
        "\n",
        "# CELL 4 - Convert annotations to YOLO format with progress tracking\n",
        "# Check if annotations already converted\n",
        "annotations_complete_flag = os.path.join(yolo_dataset_path, 'annotations_complete.txt')\n",
        "\n",
        "if os.path.exists(annotations_complete_flag):\n",
        "    print(\"Annotations already exist! Skipping annotation generation...\")\n",
        "    with open(annotations_complete_flag, 'r') as f:\n",
        "        stats = f.read()\n",
        "    print(\"\\nExisting annotation stats:\")\n",
        "    print(stats)\n",
        "else:\n",
        "    print(\"Creating YOLO annotations from masks...\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    def mask_to_bbox(mask):\n",
        "        \"\"\"Convert binary mask to bounding box coordinates\"\"\"\n",
        "        coords = np.where(mask > 127)\n",
        "        if len(coords[0]) == 0:\n",
        "            return []\n",
        "        y_min, y_max = coords[0].min(), coords[0].max()\n",
        "        x_min, x_max = coords[1].min(), coords[1].max()\n",
        "        return [(x_min, y_min, x_max, y_max)]\n",
        "\n",
        "    def bbox_to_yolo_format(bbox, img_width, img_height):\n",
        "        \"\"\"Convert bounding box to YOLO format (normalized)\"\"\"\n",
        "        x_min, y_min, x_max, y_max = bbox\n",
        "        x_center = (x_min + x_max) / 2.0\n",
        "        y_center = (y_min + y_max) / 2.0\n",
        "        width = x_max - x_min\n",
        "        height = y_max - y_min\n",
        "\n",
        "        x_center_norm = x_center / img_width\n",
        "        y_center_norm = y_center / img_height\n",
        "        width_norm = width / img_width\n",
        "        height_norm = height / img_height\n",
        "\n",
        "        return f\"0 {x_center_norm:.6f} {y_center_norm:.6f} {width_norm:.6f} {height_norm:.6f}\"\n",
        "\n",
        "    def process_dataset_split(split_name, local_dataset_path, yolo_dataset_path):\n",
        "        \"\"\"Process one split with progress tracking\"\"\"\n",
        "        img_folder = os.path.join(local_dataset_path, split_name, 'img')\n",
        "        mask_folder = os.path.join(local_dataset_path, split_name, 'masks')\n",
        "\n",
        "        print(f\"\\nProcessing {split_name}:\")\n",
        "\n",
        "        if not os.path.exists(img_folder) or not os.path.exists(mask_folder):\n",
        "            print(f\"ERROR: Missing folders for {split_name}\")\n",
        "            return 0\n",
        "\n",
        "        yolo_img_dir = os.path.join(yolo_dataset_path, split_name, 'images')\n",
        "        yolo_label_dir = os.path.join(yolo_dataset_path, split_name, 'labels')\n",
        "        os.makedirs(yolo_img_dir, exist_ok=True)\n",
        "        os.makedirs(yolo_label_dir, exist_ok=True)\n",
        "\n",
        "        img_files = [f for f in os.listdir(img_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        print(f\"Found {len(img_files)} images in {split_name}\")\n",
        "\n",
        "        processed_count = 0\n",
        "        no_plate_count = 0\n",
        "        multi_plate_count = 0\n",
        "\n",
        "        for i, img_file in enumerate(img_files):\n",
        "            # Progress update every 500 files\n",
        "            if i % 500 == 0 and i > 0:\n",
        "                print(f\"  Processed {i}/{len(img_files)} images ({i/len(img_files)*100:.1f}%)\")\n",
        "\n",
        "            try:\n",
        "                mask_name = os.path.splitext(img_file)[0] + '.png'\n",
        "                mask_path = os.path.join(mask_folder, mask_name)\n",
        "\n",
        "                if not os.path.exists(mask_path):\n",
        "                    continue\n",
        "\n",
        "                mask = cv2.imread(mask_path, 0)\n",
        "                if mask is None:\n",
        "                    continue\n",
        "\n",
        "                img_path = os.path.join(img_folder, img_file)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is None:\n",
        "                    continue\n",
        "\n",
        "                img_height, img_width = img.shape[:2]\n",
        "                bboxes = mask_to_bbox(mask)\n",
        "\n",
        "                # Copy image\n",
        "                dst_img_path = os.path.join(yolo_img_dir, img_file)\n",
        "                shutil.copy2(img_path, dst_img_path)\n",
        "\n",
        "                # Create label file\n",
        "                label_file = os.path.splitext(img_file)[0] + '.txt'\n",
        "                label_path = os.path.join(yolo_label_dir, label_file)\n",
        "\n",
        "                with open(label_path, 'w') as f:\n",
        "                    if len(bboxes) == 0:\n",
        "                        no_plate_count += 1\n",
        "                    else:\n",
        "                        if len(bboxes) > 1:\n",
        "                            multi_plate_count += 1\n",
        "                        for bbox in bboxes:\n",
        "                            yolo_line = bbox_to_yolo_format(bbox, img_width, img_height)\n",
        "                            f.write(yolo_line + '\\n')\n",
        "\n",
        "                processed_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {img_file}: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"{split_name.upper()} Summary:\")\n",
        "        print(f\"Total processed: {processed_count}\")\n",
        "        print(f\"No license plate: {no_plate_count}\")\n",
        "        print(f\"Multiple license plates: {multi_plate_count}\")\n",
        "        print(f\"Single license plate: {processed_count - no_plate_count - multi_plate_count}\")\n",
        "\n",
        "        return processed_count\n",
        "\n",
        "    # Process all splits\n",
        "    train_count = process_dataset_split('train', local_dataset_path, yolo_dataset_path)\n",
        "    val_count = process_dataset_split('validation', local_dataset_path, yolo_dataset_path)\n",
        "    test_count = process_dataset_split('test', local_dataset_path, yolo_dataset_path)\n",
        "\n",
        "    total_count = train_count + val_count + test_count\n",
        "    print(f\"\\nANNOTATION CONVERSION COMPLETED!\")\n",
        "    print(f\"Train: {train_count} images\")\n",
        "    print(f\"Validation: {val_count} images\")\n",
        "    print(f\"Test: {test_count} images\")\n",
        "    print(f\"Total: {total_count} images\")\n",
        "\n",
        "    # Save completion flag\n",
        "    stats_text = f\"\"\"ANNOTATION CONVERSION COMPLETED!\n",
        "Train: {train_count} images\n",
        "Validation: {val_count} images\n",
        "Test: {test_count} images\n",
        "Total: {total_count} images\"\"\"\n",
        "\n",
        "    with open(annotations_complete_flag, 'w') as f:\n",
        "        f.write(stats_text)\n",
        "\n",
        "    print(f\"Completion flag saved: {annotations_complete_flag}\")\n",
        "\n",
        "# CELL 5 - Create dataset configuration and verify structure\n",
        "# Create dataset.yaml configuration file\n",
        "dataset_config = {\n",
        "    'path': yolo_dataset_path,\n",
        "    'train': 'train/images',\n",
        "    'val': 'validation/images',\n",
        "    'test': 'test/images',\n",
        "    'nc': 1,\n",
        "    'names': ['license_plate']\n",
        "}\n",
        "\n",
        "config_path = os.path.join(yolo_dataset_path, 'dataset.yaml')\n",
        "with open(config_path, 'w') as f:\n",
        "    yaml.dump(dataset_config, f)\n",
        "\n",
        "print(\"Dataset configuration created!\")\n",
        "print(f\"Config saved at: {config_path}\")\n",
        "\n",
        "# Verify dataset structure\n",
        "def verify_dataset_structure():\n",
        "    \"\"\"Verify dataset is properly structured\"\"\"\n",
        "    print(\"\\nDataset Structure Verification:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for split in ['train', 'validation', 'test']:\n",
        "        img_dir = os.path.join(yolo_dataset_path, split, 'images')\n",
        "        label_dir = os.path.join(yolo_dataset_path, split, 'labels')\n",
        "\n",
        "        if os.path.exists(img_dir) and os.path.exists(label_dir):\n",
        "            img_count = len([f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "            label_count = len([f for f in os.listdir(label_dir) if f.endswith('.txt')])\n",
        "            print(f\"{split:>12}: {img_count:>4} images, {label_count:>4} labels\")\n",
        "\n",
        "            if img_count != label_count:\n",
        "                print(f\"  WARNING: Image/label count mismatch in {split}\")\n",
        "        else:\n",
        "            print(f\"  ERROR: Missing directories for {split}\")\n",
        "\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "verify_dataset_structure()\n",
        "\n",
        "# Display sample annotations for verification\n",
        "def show_sample_annotations(split_name, num_samples=2):\n",
        "    img_dir = os.path.join(yolo_dataset_path, split_name, 'images')\n",
        "    label_dir = os.path.join(yolo_dataset_path, split_name, 'labels')\n",
        "\n",
        "    if not os.path.exists(img_dir):\n",
        "        print(f\"Cannot show samples for {split_name} - directory not found\")\n",
        "        return\n",
        "\n",
        "    img_files = os.listdir(img_dir)[:num_samples]\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    for i, img_file in enumerate(img_files):\n",
        "        img_path = os.path.join(img_dir, img_file)\n",
        "        img = cv2.imread(img_path)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
        "        label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "        plt.subplot(1, num_samples, i+1)\n",
        "        plt.imshow(img_rgb)\n",
        "        plt.title(f'{split_name}: {img_file}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    parts = line.split()\n",
        "                    if len(parts) == 5:\n",
        "                        try:\n",
        "                            _, x_center, y_center, width, height = map(float, parts)\n",
        "                            x_center_px = x_center * w\n",
        "                            y_center_px = y_center * h\n",
        "                            width_px = width * w\n",
        "                            height_px = height * h\n",
        "\n",
        "                            x_min = int(x_center_px - width_px/2)\n",
        "                            y_min = int(y_center_px - height_px/2)\n",
        "                            x_max = int(x_center_px + width_px/2)\n",
        "                            y_max = int(y_center_px + height_px/2)\n",
        "\n",
        "                            import matplotlib.patches as patches\n",
        "                            rect = patches.Rectangle((x_min, y_min), width_px, height_px,\n",
        "                                                   linewidth=2, edgecolor='red', facecolor='none')\n",
        "                            plt.gca().add_patch(rect)\n",
        "                        except ValueError:\n",
        "                            continue\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nSample annotations visualization:\")\n",
        "show_sample_annotations('train', 2)\n",
        "show_sample_annotations('validation', 2)\n",
        "\n",
        "print(f\"\\nDataset ready for YOLO training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzIs442dxOo4",
        "outputId": "7486586a-430b-4550-c389-23db8d07b307"
      },
      "outputs": [],
      "source": [
        "# CELL 6 - Enhanced YOLO Training with Optimized Hyperparameters\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import shutil\n",
        "import os\n",
        "import json\n",
        "import threading\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Setup paths\n",
        "model_save_dir = '/content/yolo_models'\n",
        "checkpoint_dir = '/content/drive/MyDrive/yolo_checkpoints'\n",
        "progress_file = os.path.join(checkpoint_dir, 'training_progress.json')\n",
        "\n",
        "os.makedirs(model_save_dir, exist_ok=True)\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "print(f\"Checkpoint directory: {checkpoint_dir}\")\n",
        "\n",
        "# Check GPU memory and recommend batch size\n",
        "if torch.cuda.is_available():\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
        "\n",
        "    # Recommend batch size based on GPU memory\n",
        "    if gpu_memory < 8:\n",
        "        recommended_batch = 4\n",
        "        print(\"WARNING: Low GPU memory detected. Using batch size 4.\")\n",
        "    elif gpu_memory < 12:\n",
        "        recommended_batch = 6\n",
        "        print(\"Moderate GPU memory. Using batch size 6.\")\n",
        "    else:\n",
        "        recommended_batch = 8\n",
        "        print(\"High GPU memory. Using batch size 8.\")\n",
        "else:\n",
        "    recommended_batch = 4\n",
        "    print(\"No GPU detected. Using batch size 4.\")\n",
        "\n",
        "def save_training_progress(stage, epoch, status=\"in_progress\"):\n",
        "    \"\"\"Save training progress to Drive\"\"\"\n",
        "    progress_data = {\n",
        "        'stage': stage,\n",
        "        'completed_epochs': epoch,\n",
        "        'status': status,\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'stage1_epochs': 20,\n",
        "        'stage2_epochs': 50\n",
        "    }\n",
        "\n",
        "    with open(progress_file, 'w') as f:\n",
        "        json.dump(progress_data, f, indent=2)\n",
        "    print(f\"Progress saved: Stage {stage}, Epoch {epoch}\")\n",
        "\n",
        "def load_training_progress():\n",
        "    \"\"\"Load training progress from Drive\"\"\"\n",
        "    if os.path.exists(progress_file):\n",
        "        with open(progress_file, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return None\n",
        "\n",
        "def get_best_checkpoint(stage):\n",
        "    \"\"\"Get the best checkpoint for a stage\"\"\"\n",
        "    stage_dir = os.path.join(checkpoint_dir, f'stage{stage}')\n",
        "    best_pt = os.path.join(stage_dir, 'weights', 'best.pt')\n",
        "    last_pt = os.path.join(stage_dir, 'weights', 'last.pt')\n",
        "\n",
        "    if os.path.exists(best_pt):\n",
        "        return best_pt\n",
        "    elif os.path.exists(last_pt):\n",
        "        return last_pt\n",
        "    return None\n",
        "\n",
        "def copy_checkpoint_to_drive(stage, epoch):\n",
        "    \"\"\"Copy checkpoint to Drive with enhanced logging\"\"\"\n",
        "    local_stage_dir = os.path.join(model_save_dir, f'stage{stage}')\n",
        "    drive_stage_dir = os.path.join(checkpoint_dir, f'stage{stage}')\n",
        "\n",
        "    if os.path.exists(local_stage_dir):\n",
        "        try:\n",
        "            # Copy entire stage directory\n",
        "            if os.path.exists(drive_stage_dir):\n",
        "                shutil.rmtree(drive_stage_dir)\n",
        "            shutil.copytree(local_stage_dir, drive_stage_dir)\n",
        "\n",
        "            # Save progress\n",
        "            save_training_progress(stage, epoch)\n",
        "            print(f\"Checkpoint saved to Drive: Stage {stage}, Epoch {epoch}\")\n",
        "\n",
        "            # Log checkpoint size for verification\n",
        "            checkpoint_size = sum(os.path.getsize(os.path.join(dirpath, filename))\n",
        "                                for dirpath, dirnames, filenames in os.walk(drive_stage_dir)\n",
        "                                for filename in filenames) / (1024**2)  # MB\n",
        "            print(f\"   Checkpoint size: {checkpoint_size:.1f} MB\")\n",
        "\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to save checkpoint: {e}\")\n",
        "            return False\n",
        "    return False\n",
        "\n",
        "def get_training_epoch_from_logs(stage_dir):\n",
        "    \"\"\"Estimate current epoch from training logs\"\"\"\n",
        "    results_file = os.path.join(stage_dir, 'results.csv')\n",
        "    if os.path.exists(results_file):\n",
        "        try:\n",
        "            with open(results_file, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "                return len(lines) - 1  # Subtract header\n",
        "        except:\n",
        "            pass\n",
        "    return 0\n",
        "\n",
        "# Load previous progress\n",
        "progress = load_training_progress()\n",
        "start_stage = 1\n",
        "resume_model_path = None\n",
        "\n",
        "if progress:\n",
        "    print(f\"\\nFound previous training progress:\")\n",
        "    print(f\"   Last stage: {progress['stage']}\")\n",
        "    print(f\"   Last epoch: {progress['completed_epochs']}\")\n",
        "    print(f\"   Status: {progress['status']}\")\n",
        "    print(f\"   Timestamp: {progress['timestamp']}\")\n",
        "\n",
        "    if progress['status'] == 'completed':\n",
        "        print(\"Training already completed!\")\n",
        "        # Load the final model\n",
        "        final_model_path = os.path.join(checkpoint_dir, 'final_model.pt')\n",
        "        if os.path.exists(final_model_path):\n",
        "            trained_model = YOLO(final_model_path)\n",
        "            print(\"Loaded final trained model\")\n",
        "        else:\n",
        "            print(\"Final model not found, will retrain\")\n",
        "    else:\n",
        "        # Determine where to resume\n",
        "        if progress['stage'] == 1:\n",
        "            if progress['completed_epochs'] >= 20:\n",
        "                # Stage 1 completed, start Stage 2\n",
        "                start_stage = 2\n",
        "                resume_model_path = get_best_checkpoint(1)\n",
        "                print(f\"Resuming from Stage 2 with model: {resume_model_path}\")\n",
        "            else:\n",
        "                # Resume Stage 1\n",
        "                start_stage = 1\n",
        "                resume_model_path = get_best_checkpoint(1)\n",
        "                if resume_model_path:\n",
        "                    print(f\"Resuming Stage 1 from epoch {progress['completed_epochs']} with model: {resume_model_path}\")\n",
        "                else:\n",
        "                    print(\"Restarting Stage 1 (no valid checkpoint found)\")\n",
        "        elif progress['stage'] == 2:\n",
        "            if progress['completed_epochs'] >= 50:\n",
        "                print(\"Training already completed!\")\n",
        "            else:\n",
        "                # Resume Stage 2\n",
        "                start_stage = 2\n",
        "                resume_model_path = get_best_checkpoint(2)\n",
        "                if resume_model_path:\n",
        "                    print(f\"Resuming Stage 2 from epoch {progress['completed_epochs']} with model: {resume_model_path}\")\n",
        "                else:\n",
        "                    # Fall back to Stage 1 model\n",
        "                    resume_model_path = get_best_checkpoint(1)\n",
        "                    print(f\"Restarting Stage 2 with Stage 1 model: {resume_model_path}\")\n",
        "\n",
        "# Global variable to control monitoring thread\n",
        "monitoring_active = False\n",
        "\n",
        "def monitor_training_stage(stage, max_epochs):\n",
        "    \"\"\"Monitor training and save checkpoints every 10 epochs\"\"\"\n",
        "    global monitoring_active\n",
        "    stage_dir = os.path.join(model_save_dir, f'stage{stage}')\n",
        "    last_saved_epoch = 0\n",
        "    check_interval = 30  # Check every 30 seconds\n",
        "\n",
        "    print(f\"Starting training monitor for Stage {stage}\")\n",
        "    print(f\"   Will save checkpoints every 10 epochs\")\n",
        "\n",
        "    while monitoring_active:\n",
        "        try:\n",
        "            time.sleep(check_interval)\n",
        "\n",
        "            if not monitoring_active:\n",
        "                break\n",
        "\n",
        "            if os.path.exists(stage_dir):\n",
        "                # Get current epoch from logs\n",
        "                current_epoch = get_training_epoch_from_logs(stage_dir)\n",
        "\n",
        "                # Save checkpoint every 10 epochs\n",
        "                if current_epoch > 0 and current_epoch % 10 == 0 and current_epoch > last_saved_epoch:\n",
        "                    success = copy_checkpoint_to_drive(stage, current_epoch)\n",
        "                    if success:\n",
        "                        last_saved_epoch = current_epoch\n",
        "                        print(f\"Auto-checkpoint saved: Stage {stage}, Epoch {current_epoch}\")\n",
        "\n",
        "                # Additional safety checkpoints\n",
        "                safety_epochs = []\n",
        "                if stage == 1:\n",
        "                    safety_epochs = [5, 15]  # 25% and 75% of 20 epochs\n",
        "                elif stage == 2:\n",
        "                    safety_epochs = [12, 25, 37]  # 25%, 50%, 75% of 50 epochs\n",
        "\n",
        "                if current_epoch in safety_epochs and current_epoch > last_saved_epoch:\n",
        "                    success = copy_checkpoint_to_drive(stage, current_epoch)\n",
        "                    if success:\n",
        "                        last_saved_epoch = current_epoch\n",
        "                        print(f\"Safety checkpoint: Stage {stage}, Epoch {current_epoch}\")\n",
        "\n",
        "                # Check if training completed\n",
        "                if current_epoch >= max_epochs:\n",
        "                    print(f\"Training appears complete for Stage {stage}\")\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Monitor error: {e}\")\n",
        "            time.sleep(60)\n",
        "\n",
        "    print(f\"Training monitor stopped for Stage {stage}\")\n",
        "\n",
        "# STAGE 1: Warm-up with optimized hyperparameters\n",
        "if start_stage <= 1:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STAGE 1: Warm-up Training (20 epochs)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Load appropriate model\n",
        "    if resume_model_path and start_stage == 1:\n",
        "        model = YOLO(resume_model_path)\n",
        "        print(f\"Loaded checkpoint: {resume_model_path}\")\n",
        "    else:\n",
        "        # Use YOLOv8s instead of YOLOv8l for small dataset\n",
        "        model = YOLO('yolov8m.pt')  # Changed from yolov8l.pt\n",
        "        print(\"Loaded YOLOv8m model (optimized for small datasets)\")\n",
        "\n",
        "    # Start monitoring thread\n",
        "    monitoring_active = True\n",
        "    monitor_thread = threading.Thread(target=monitor_training_stage, args=(1, 20), daemon=True)\n",
        "    monitor_thread.start()\n",
        "\n",
        "    try:\n",
        "        results = model.train(\n",
        "            data=config_path,\n",
        "            epochs=20,\n",
        "            batch=recommended_batch,\n",
        "            name='stage1',\n",
        "            project=model_save_dir,\n",
        "            save_period=10,\n",
        "            freeze=8,        # Freeze fewer layers (was 10)\n",
        "            lr0=0.002,       # Much lower learning rate (was 0.01)\n",
        "            lrf=0.1,         # Final learning rate factor\n",
        "            momentum=0.937,  # Standard momentum\n",
        "            weight_decay=0.0005,  # L2 regularization\n",
        "            warmup_epochs=3, # Warmup for stability\n",
        "            warmup_momentum=0.8,\n",
        "            warmup_bias_lr=0.1,\n",
        "            box=7.5,         # Box loss weight\n",
        "            cls=0.5,         # Class loss weight\n",
        "            dfl=1.5,         # DFL loss weight\n",
        "            # Enhanced augmentations for small dataset\n",
        "            hsv_h=0.015,     # Hue augmentation\n",
        "            hsv_s=0.7,       # Saturation augmentation\n",
        "            hsv_v=0.4,       # Value augmentation\n",
        "            degrees=10,      # Rotation degrees\n",
        "            translate=0.1,   # Translation\n",
        "            scale=0.5,       # Scale augmentation\n",
        "            shear=2,         # Shear degrees\n",
        "            perspective=0.0, # Perspective (disable for license plates)\n",
        "            flipud=0.0,      # Disable vertical flip (bad for text)\n",
        "            fliplr=0.5,      # Horizontal flip\n",
        "            mosaic=1.0,      # Mosaic augmentation\n",
        "            mixup=0.1,       # Mixup augmentation\n",
        "            copy_paste=0.3,  # Copy-paste augmentation\n",
        "            patience=15,     # Increased patience\n",
        "            exist_ok=True,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        # Stop monitoring\n",
        "        monitoring_active = False\n",
        "        time.sleep(2)\n",
        "\n",
        "        # Save final Stage 1 checkpoint\n",
        "        copy_checkpoint_to_drive(1, 20)\n",
        "        print(\"Stage 1 completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Stop monitoring\n",
        "        monitoring_active = False\n",
        "        print(f\"Stage 1 failed: {e}\")\n",
        "\n",
        "        # Try to save current progress\n",
        "        try:\n",
        "            stage1_dir = os.path.join(model_save_dir, 'stage1')\n",
        "            current_epoch = get_training_epoch_from_logs(stage1_dir)\n",
        "            if current_epoch > 0:\n",
        "                copy_checkpoint_to_drive(1, current_epoch)\n",
        "            save_training_progress(1, current_epoch, \"failed\")\n",
        "        except:\n",
        "            save_training_progress(1, 0, \"failed\")\n",
        "        raise e\n",
        "\n",
        "# STAGE 2: Full training with fine-tuned parameters\n",
        "if start_stage <= 2:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STAGE 2: Full Training (50 epochs)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Determine which model to load for Stage 2\n",
        "    if start_stage == 2 and resume_model_path:\n",
        "        # Resuming Stage 2\n",
        "        model = YOLO(resume_model_path)\n",
        "        print(f\"Resuming with: {resume_model_path}\")\n",
        "    else:\n",
        "        # Starting Stage 2 fresh\n",
        "        stage1_best = get_best_checkpoint(1)\n",
        "        if stage1_best:\n",
        "            model = YOLO(stage1_best)\n",
        "            print(f\"Loading Stage 1 best: {stage1_best}\")\n",
        "        else:\n",
        "            # Fallback\n",
        "            stage1_local = os.path.join(model_save_dir, 'stage1', 'weights', 'best.pt')\n",
        "            if os.path.exists(stage1_local):\n",
        "                model = YOLO(stage1_local)\n",
        "                print(f\"Loading local Stage 1: {stage1_local}\")\n",
        "            else:\n",
        "                model = YOLO('yolov8m.pt')\n",
        "                print(\"No Stage 1 model found, using fresh YOLOv8m\")\n",
        "\n",
        "    # Start enhanced monitoring for Stage 2\n",
        "    monitoring_active = True\n",
        "    monitor_thread = threading.Thread(target=monitor_training_stage, args=(2, 50), daemon=True)\n",
        "    monitor_thread.start()\n",
        "\n",
        "    try:\n",
        "        results = model.train(\n",
        "            data=config_path,\n",
        "            epochs=50,\n",
        "            batch=recommended_batch,\n",
        "            name='stage2',\n",
        "            project=model_save_dir,\n",
        "            save_period=10,\n",
        "            freeze=0,        # Unfreeze all layers\n",
        "            lr0=0.0005,      # Very low learning rate for fine-tuning (was 0.001)\n",
        "            lrf=0.01,        # Final learning rate factor\n",
        "            momentum=0.937,\n",
        "            weight_decay=0.0005,\n",
        "            warmup_epochs=0, # No warmup needed in stage 2\n",
        "            box=7.5,\n",
        "            cls=0.5,\n",
        "            dfl=1.5,\n",
        "            # Reduced augmentation for fine-tuning\n",
        "            hsv_h=0.01,      # Reduced hue augmentation\n",
        "            hsv_s=0.5,       # Reduced saturation\n",
        "            hsv_v=0.3,       # Reduced value\n",
        "            degrees=5,       # Reduced rotation\n",
        "            translate=0.05,  # Reduced translation\n",
        "            scale=0.3,       # Reduced scale\n",
        "            shear=1,         # Reduced shear\n",
        "            perspective=0.0,\n",
        "            flipud=0.0,\n",
        "            fliplr=0.3,      # Reduced horizontal flip\n",
        "            mosaic=0.8,      # Reduced mosaic\n",
        "            mixup=0.05,      # Reduced mixup\n",
        "            copy_paste=0.1,  # Reduced copy-paste\n",
        "            patience=25,     # Higher patience for longer training\n",
        "            exist_ok=True,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        # Stop monitoring\n",
        "        monitoring_active = False\n",
        "        time.sleep(2)\n",
        "\n",
        "        # Save final Stage 2 checkpoint and mark as completed\n",
        "        copy_checkpoint_to_drive(2, 50)\n",
        "\n",
        "        # Save final model\n",
        "        stage2_best = os.path.join(model_save_dir, 'stage2', 'weights', 'best.pt')\n",
        "        final_model_drive = os.path.join(checkpoint_dir, 'final_model.pt')\n",
        "\n",
        "        if os.path.exists(stage2_best):\n",
        "            shutil.copy2(stage2_best, final_model_drive)\n",
        "            print(\"Final model saved to Drive\")\n",
        "\n",
        "        # Mark training as completed\n",
        "        save_training_progress(2, 50, \"completed\")\n",
        "        print(\"Stage 2 completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Stop monitoring\n",
        "        monitoring_active = False\n",
        "        print(f\"Stage 2 failed: {e}\")\n",
        "\n",
        "        # Try to save current progress\n",
        "        try:\n",
        "            stage2_dir = os.path.join(model_save_dir, 'stage2')\n",
        "            current_epoch = get_training_epoch_from_logs(stage2_dir)\n",
        "            if current_epoch > 0:\n",
        "                copy_checkpoint_to_drive(2, current_epoch)\n",
        "            save_training_progress(2, current_epoch, \"failed\")\n",
        "        except:\n",
        "            save_training_progress(2, 0, \"failed\")\n",
        "        raise e\n",
        "\n",
        "# Load the final trained model\n",
        "final_model_path = os.path.join(checkpoint_dir, 'final_model.pt')\n",
        "if os.path.exists(final_model_path):\n",
        "    trained_model = YOLO(final_model_path)\n",
        "    print(\"Final trained model loaded successfully!\")\n",
        "else:\n",
        "    # Fallback to local model\n",
        "    local_best = os.path.join(model_save_dir, 'stage2', 'weights', 'best.pt')\n",
        "    if os.path.exists(local_best):\n",
        "        trained_model = YOLO(local_best)\n",
        "        print(\"Loaded local trained model\")\n",
        "    else:\n",
        "        print(\"No trained model found!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING PIPELINE COMPLETED!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Check training progress: {progress_file}\")\n",
        "print(f\"Models saved in: {checkpoint_dir}\")\n",
        "print(f\"Final model: {final_model_path}\")\n",
        "\n",
        "# Clean up\n",
        "monitoring_active = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEjteSj7waQC",
        "outputId": "91bfdd22-ab09-47fe-c104-6928de38bab6"
      },
      "outputs": [],
      "source": [
        "# CELL 7 - Simple Comprehensive Evaluation\n",
        "# Add these helper functions BEFORE the evaluate_model function in Cell 7\n",
        "\n",
        "def load_ground_truth_boxes(label_path, img_width, img_height):\n",
        "    \"\"\"Load ground truth boxes from YOLO format label file\"\"\"\n",
        "    boxes = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                parts = line.split()\n",
        "                if len(parts) == 5:\n",
        "                    try:\n",
        "                        _, x_center, y_center, width, height = map(float, parts)\n",
        "\n",
        "                        # Convert from YOLO format to absolute coordinates\n",
        "                        x_center_abs = x_center * img_width\n",
        "                        y_center_abs = y_center * img_height\n",
        "                        width_abs = width * img_width\n",
        "                        height_abs = height * img_height\n",
        "\n",
        "                        # Convert to corner coordinates [x1, y1, x2, y2]\n",
        "                        x1 = x_center_abs - width_abs / 2\n",
        "                        y1 = y_center_abs - height_abs / 2\n",
        "                        x2 = x_center_abs + width_abs / 2\n",
        "                        y2 = y_center_abs + height_abs / 2\n",
        "\n",
        "                        boxes.append([x1, y1, x2, y2])\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "    return boxes\n",
        "\n",
        "def calculate_box_iou(box1, box2):\n",
        "    \"\"\"Calculate IoU between two bounding boxes\"\"\"\n",
        "    x1_1, y1_1, x2_1, y2_1 = box1\n",
        "    x1_2, y1_2, x2_2, y2_2 = box2\n",
        "\n",
        "    # Calculate intersection coordinates\n",
        "    x1_i = max(x1_1, x1_2)\n",
        "    y1_i = max(y1_1, y1_2)\n",
        "    x2_i = min(x2_1, x2_2)\n",
        "    y2_i = min(y2_1, y2_2)\n",
        "\n",
        "    # Check if there's intersection\n",
        "    if x2_i <= x1_i or y2_i <= y1_i:\n",
        "        return 0.0\n",
        "\n",
        "    # Calculate intersection area\n",
        "    intersection_area = (x2_i - x1_i) * (y2_i - y1_i)\n",
        "\n",
        "    # Calculate areas of both boxes\n",
        "    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "\n",
        "    # Calculate union area\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "\n",
        "    # Calculate IoU\n",
        "    if union_area == 0:\n",
        "        return 0.0\n",
        "\n",
        "    iou = intersection_area / union_area\n",
        "    return iou\n",
        "\n",
        "def evaluate_model(model, split_name, conf_thresh=0.5):\n",
        "    \"\"\"Simple but comprehensive evaluation\"\"\"\n",
        "    img_dir = f'{yolo_dataset_path}/{split_name}/images'\n",
        "    label_dir = f'{yolo_dataset_path}/{split_name}/labels'\n",
        "\n",
        "    img_files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "    tp, fp, fn, tn = 0, 0, 0, 0\n",
        "    iou_scores = []\n",
        "\n",
        "    print(f\"Evaluating {len(img_files)} images...\")\n",
        "\n",
        "    for i, img_file in enumerate(img_files):\n",
        "        if i % 500 == 0 and i > 0:\n",
        "            print(f\"Progress: {i}/{len(img_files)}\")\n",
        "\n",
        "        img_path = f'{img_dir}/{img_file}'\n",
        "        label_path = f'{label_dir}/{os.path.splitext(img_file)[0]}.txt'\n",
        "\n",
        "        # Load image and get dimensions\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None: continue\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        # Load ground truth\n",
        "        gt_boxes = load_ground_truth_boxes(label_path, w, h)\n",
        "        has_gt = len(gt_boxes) > 0\n",
        "\n",
        "        # Get predictions\n",
        "        results = model(img_path, conf=conf_thresh, verbose=False)\n",
        "        pred_boxes = []\n",
        "        if results[0].boxes is not None:\n",
        "            for box in results[0].boxes:\n",
        "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                pred_boxes.append([x1, y1, x2, y2])\n",
        "        has_pred = len(pred_boxes) > 0\n",
        "\n",
        "        # Calculate IoU and metrics\n",
        "        if has_gt and has_pred:\n",
        "            max_iou = 0\n",
        "            for gt_box in gt_boxes:\n",
        "                for pred_box in pred_boxes:\n",
        "                    iou = calculate_box_iou(gt_box, pred_box)\n",
        "                    max_iou = max(max_iou, iou)\n",
        "\n",
        "            iou_scores.append(max_iou)\n",
        "            if max_iou > 0.5:\n",
        "                tp += 1\n",
        "            else:\n",
        "                fn += 1\n",
        "        elif has_gt and not has_pred:\n",
        "            fn += 1\n",
        "            iou_scores.append(0)\n",
        "        elif not has_gt and has_pred:\n",
        "            fp += 1\n",
        "            iou_scores.append(0)\n",
        "        else:\n",
        "            tn += 1\n",
        "            iou_scores.append(1)\n",
        "\n",
        "    # Calculate final metrics\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    accuracy = (tp + tn) / len(img_files)\n",
        "    avg_iou = sum(iou_scores) / len(iou_scores)\n",
        "\n",
        "    # Binary detection (IoU > 0.7, same as U-Net)\n",
        "    binary_detection = sum(1 for iou in iou_scores if iou > 0.7) / len(iou_scores)\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'accuracy': accuracy,\n",
        "        'avg_iou': avg_iou,\n",
        "        'binary_detection': binary_detection,\n",
        "        'iou_scores': iou_scores\n",
        "    }\n",
        "\n",
        "# Evaluate on test and validation\n",
        "print(\"Evaluating model...\")\n",
        "val_results = evaluate_model(trained_model, 'validation')\n",
        "test_results = evaluate_model(trained_model, 'test')\n",
        "\n",
        "print(\"\\nVALIDATION RESULTS:\")\n",
        "print(f\"IoU: {val_results['avg_iou']:.4f}\")\n",
        "print(f\"Precision: {val_results['precision']:.4f}\")\n",
        "print(f\"Recall: {val_results['recall']:.4f}\")\n",
        "print(f\"F1-Score: {val_results['f1_score']:.4f}\")\n",
        "print(f\"Binary Detection (IoU>0.7): {val_results['binary_detection']:.4f}\")\n",
        "\n",
        "print(\"\\nTEST RESULTS:\")\n",
        "print(f\"IoU: {test_results['avg_iou']:.4f}\")\n",
        "print(f\"Precision: {test_results['precision']:.4f}\")\n",
        "print(f\"Recall: {test_results['recall']:.4f}\")\n",
        "print(f\"F1-Score: {test_results['f1_score']:.4f}\")\n",
        "print(f\"Binary Detection (IoU>0.7): {test_results['binary_detection']:.4f}\")\n",
        "print(f\"Boundary Box Accuracy: {test_results['binary_detection']*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "6xKSb_Tjxi8v",
        "outputId": "a6a6e077-13ed-425a-b906-f63245fd75cd"
      },
      "outputs": [],
      "source": [
        "# CELL 8 - Simple Training Visualization (Updated for new epoch counts)\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load training results\n",
        "stage1_csv = f'{model_save_dir}/stage1/results.csv'\n",
        "stage2_csv = f'{model_save_dir}/stage2/results.csv'\n",
        "\n",
        "if os.path.exists(stage1_csv) and os.path.exists(stage2_csv):\n",
        "    stage1_data = pd.read_csv(stage1_csv)\n",
        "    stage2_data = pd.read_csv(stage2_csv)\n",
        "    all_data = pd.concat([stage1_data, stage2_data], ignore_index=True)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
        "    epochs = range(1, len(all_data) + 1)\n",
        "    stage1_end = len(stage1_data)\n",
        "\n",
        "    # Loss\n",
        "    axes[0,0].plot(epochs, all_data['train/box_loss'], 'b-', label='Train')\n",
        "    if 'val/box_loss' in all_data.columns:\n",
        "        axes[0,0].plot(epochs, all_data['val/box_loss'], 'r-', label='Val')\n",
        "    axes[0,0].axvline(x=stage1_end, color='green', linestyle='--', alpha=0.5, label=f'Stage 1 End (Epoch {stage1_end})')\n",
        "    axes[0,0].set_title('Box Loss')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # mAP (IoU equivalent)\n",
        "    axes[0,1].plot(epochs, all_data['metrics/mAP50(B)'], 'g-', label='mAP@0.5')\n",
        "    axes[0,1].axvline(x=stage1_end, color='green', linestyle='--', alpha=0.5)\n",
        "    axes[0,1].set_title('mAP@0.5 (IoU Equivalent)')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Precision & Recall\n",
        "    axes[0,2].plot(epochs, all_data['metrics/precision(B)'], 'purple', label='Precision')\n",
        "    axes[0,2].plot(epochs, all_data['metrics/recall(B)'], 'brown', label='Recall')\n",
        "    axes[0,2].axvline(x=stage1_end, color='green', linestyle='--', alpha=0.5)\n",
        "    axes[0,2].set_title('Precision & Recall')\n",
        "    axes[0,2].legend()\n",
        "    axes[0,2].grid(True, alpha=0.3)\n",
        "\n",
        "    # F1-Score\n",
        "    precision = all_data['metrics/precision(B)']\n",
        "    recall = all_data['metrics/recall(B)']\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    f1 = f1.fillna(0)\n",
        "\n",
        "    axes[1,0].plot(epochs, f1, 'cyan', label='F1-Score')\n",
        "    axes[1,0].axvline(x=stage1_end, color='green', linestyle='--', alpha=0.5)\n",
        "    axes[1,0].set_title('F1-Score')\n",
        "    axes[1,0].legend()\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Learning Rate\n",
        "    axes[1,1].plot(epochs, all_data['lr/pg0'], 'magenta', label='Learning Rate')\n",
        "    axes[1,1].axvline(x=stage1_end, color='green', linestyle='--', alpha=0.5)\n",
        "    axes[1,1].set_title('Learning Rate')\n",
        "    axes[1,1].legend()\n",
        "    axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Final Performance Bar\n",
        "    metrics = ['IoU', 'Precision', 'Recall', 'F1', 'Binary Det']\n",
        "    val_scores = [val_results['avg_iou'], val_results['precision'],\n",
        "                  val_results['recall'], val_results['f1_score'], val_results['binary_detection']]\n",
        "    test_scores = [test_results['avg_iou'], test_results['precision'],\n",
        "                   test_results['recall'], test_results['f1_score'], test_results['binary_detection']]\n",
        "\n",
        "    x = range(len(metrics))\n",
        "    width = 0.35\n",
        "    axes[1,2].bar([i-width/2 for i in x], val_scores, width, label='Val', alpha=0.7)\n",
        "    axes[1,2].bar([i+width/2 for i in x], test_scores, width, label='Test', alpha=0.7)\n",
        "    axes[1,2].set_title('Final Performance')\n",
        "    axes[1,2].set_xticks(x)\n",
        "    axes[1,2].set_xticklabels(metrics, rotation=45)\n",
        "    axes[1,2].legend()\n",
        "    axes[1,2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Updated Summary\n",
        "    print(\"\\nTRAINING SUMMARY:\")\n",
        "    print(f\"Total epochs: {len(all_data)} (Stage 1: 20, Stage 2: 50)\")  # Updated\n",
        "    print(f\"Batch size used: 8\")  # Updated\n",
        "    print(f\"Checkpoint frequency: Every 10 epochs\")  # Updated\n",
        "    print(f\"Best mAP@0.5: {all_data['metrics/mAP50(B)'].max():.4f}\")\n",
        "    print(f\"Best Precision: {all_data['metrics/precision(B)'].max():.4f}\")\n",
        "    print(f\"Best Recall: {all_data['metrics/recall(B)'].max():.4f}\")\n",
        "    print(f\"Final Test IoU: {test_results['avg_iou']:.4f}\")\n",
        "    print(f\"Stage 1 completed at epoch: {stage1_end}\")\n",
        "    print(f\"Total training epochs: {len(all_data)}\")\n",
        "\n",
        "print(\"Enhanced YOLO training completed!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
