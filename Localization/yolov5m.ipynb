{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m_Pm8_4Eguj",
        "outputId": "b599575d-66b8-41bc-cd15-fc3eff29d318"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install dependencies and setup for YOLOv5\n",
        "import os\n",
        "\n",
        "# Clone YOLOv5 if not already cloned\n",
        "if not os.path.exists('/content/yolov5'):\n",
        "    !git clone https://github.com/ultralytics/yolov5.git /content/yolov5\n",
        "    print(\"YOLOv5 cloned successfully!\")\n",
        "else:\n",
        "    print(\"YOLOv5 already exists!\")\n",
        "\n",
        "%cd /content/yolov5\n",
        "\n",
        "# Install requirements\n",
        "!pip install -qr requirements.txt\n",
        "\n",
        "# Additional packages\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Additional imports\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files, drive\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "print(\"All dependencies installed successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "# Cell 2: Mount Drive and setup paths\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "local_dataset_path = '/content/Bangla_License_Plate_Dataset'\n",
        "yolo_dataset_path = '/content/yolo_dataset'\n",
        "drive_backup_path = '/content/drive/MyDrive/Bangla_License_Plate_Dataset'\n",
        "\n",
        "print(\"Drive mounted successfully!\")\n",
        "\n",
        "# Cell 3: Download and prepare dataset (same as original)\n",
        "dataset_ready = False\n",
        "\n",
        "if os.path.exists(local_dataset_path):\n",
        "    print(\"Dataset already exists locally\")\n",
        "    dataset_ready = True\n",
        "elif os.path.exists(drive_backup_path):\n",
        "    print(\"Copying dataset from Drive to local storage...\")\n",
        "    shutil.copytree(drive_backup_path, local_dataset_path)\n",
        "    print(\"Dataset copied to local storage\")\n",
        "    dataset_ready = True\n",
        "else:\n",
        "    print(\"Dataset not found. Please upload your kaggle.json file:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "    shutil.move('kaggle.json', '/root/.kaggle/kaggle.json')\n",
        "    os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
        "\n",
        "    print(\"Downloading dataset from Kaggle...\")\n",
        "    os.system('kaggle datasets download -d nishat99/bangla-license-plate-detection -p /content')\n",
        "    os.system('unzip -q /content/bangla-license-plate-detection.zip -d /content')\n",
        "\n",
        "    if os.path.exists('/content/Bangla License Plate Dataset'):\n",
        "        shutil.move('/content/Bangla License Plate Dataset', local_dataset_path)\n",
        "        dataset_ready = True\n",
        "\n",
        "        try:\n",
        "            shutil.copytree(local_dataset_path, drive_backup_path)\n",
        "            print(\"Dataset backed up to Drive\")\n",
        "        except:\n",
        "            print(\"Drive backup failed, continuing with local dataset\")\n",
        "\n",
        "if not dataset_ready:\n",
        "    print(\"ERROR: Dataset preparation failed!\")\n",
        "else:\n",
        "    print(f\"Dataset ready at: {local_dataset_path}\")\n",
        "\n",
        "# Cell 4: Convert annotations to YOLO format (same as original)\n",
        "def mask_to_bbox(mask):\n",
        "    \"\"\"Convert binary mask to bounding box coordinates\"\"\"\n",
        "    coords = np.where(mask > 127)\n",
        "    if len(coords[0]) == 0:\n",
        "        return []\n",
        "    y_min, y_max = coords[0].min(), coords[0].max()\n",
        "    x_min, x_max = coords[1].min(), coords[1].max()\n",
        "    return [(x_min, y_min, x_max, y_max)]\n",
        "\n",
        "def bbox_to_yolo_format(bbox, img_width, img_height):\n",
        "    \"\"\"Convert bounding box to YOLO format (normalized)\"\"\"\n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "    x_center = (x_min + x_max) / 2.0\n",
        "    y_center = (y_min + y_max) / 2.0\n",
        "    width = x_max - x_min\n",
        "    height = y_max - y_min\n",
        "\n",
        "    x_center_norm = x_center / img_width\n",
        "    y_center_norm = y_center / img_height\n",
        "    width_norm = width / img_width\n",
        "    height_norm = height / img_height\n",
        "\n",
        "    return f\"0 {x_center_norm:.6f} {y_center_norm:.6f} {width_norm:.6f} {height_norm:.6f}\"\n",
        "\n",
        "def process_dataset_split(split_name, local_dataset_path, yolo_dataset_path):\n",
        "    \"\"\"Process one split with progress tracking\"\"\"\n",
        "    img_folder = os.path.join(local_dataset_path, split_name, 'img')\n",
        "    mask_folder = os.path.join(local_dataset_path, split_name, 'masks')\n",
        "\n",
        "    print(f\"\\nProcessing {split_name}:\")\n",
        "\n",
        "    if not os.path.exists(img_folder) or not os.path.exists(mask_folder):\n",
        "        print(f\"ERROR: Missing folders for {split_name}\")\n",
        "        return 0\n",
        "\n",
        "    yolo_img_dir = os.path.join(yolo_dataset_path, split_name, 'images')\n",
        "    yolo_label_dir = os.path.join(yolo_dataset_path, split_name, 'labels')\n",
        "    os.makedirs(yolo_img_dir, exist_ok=True)\n",
        "    os.makedirs(yolo_label_dir, exist_ok=True)\n",
        "\n",
        "    img_files = [f for f in os.listdir(img_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    print(f\"Found {len(img_files)} images in {split_name}\")\n",
        "\n",
        "    processed_count = 0\n",
        "\n",
        "    for i, img_file in enumerate(img_files):\n",
        "        if i % 500 == 0 and i > 0:\n",
        "            print(f\"  Processed {i}/{len(img_files)} images ({i/len(img_files)*100:.1f}%)\")\n",
        "\n",
        "        try:\n",
        "            mask_name = os.path.splitext(img_file)[0] + '.png'\n",
        "            mask_path = os.path.join(mask_folder, mask_name)\n",
        "\n",
        "            if not os.path.exists(mask_path):\n",
        "                continue\n",
        "\n",
        "            mask = cv2.imread(mask_path, 0)\n",
        "            if mask is None:\n",
        "                continue\n",
        "\n",
        "            img_path = os.path.join(img_folder, img_file)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            img_height, img_width = img.shape[:2]\n",
        "            bboxes = mask_to_bbox(mask)\n",
        "\n",
        "            # Copy image\n",
        "            dst_img_path = os.path.join(yolo_img_dir, img_file)\n",
        "            shutil.copy2(img_path, dst_img_path)\n",
        "\n",
        "            # Create label file\n",
        "            label_file = os.path.splitext(img_file)[0] + '.txt'\n",
        "            label_path = os.path.join(yolo_label_dir, label_file)\n",
        "\n",
        "            with open(label_path, 'w') as f:\n",
        "                for bbox in bboxes:\n",
        "                    yolo_line = bbox_to_yolo_format(bbox, img_width, img_height)\n",
        "                    f.write(yolo_line + '\\n')\n",
        "\n",
        "            processed_count += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_file}: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"{split_name.upper()} processed: {processed_count} images\")\n",
        "    return processed_count\n",
        "\n",
        "# Check if annotations already converted\n",
        "annotations_complete_flag = os.path.join(yolo_dataset_path, 'annotations_complete.txt')\n",
        "\n",
        "if os.path.exists(annotations_complete_flag):\n",
        "    print(\"Annotations already exist! Skipping annotation generation...\")\n",
        "else:\n",
        "    print(\"Creating YOLO annotations from masks...\")\n",
        "\n",
        "    train_count = process_dataset_split('train', local_dataset_path, yolo_dataset_path)\n",
        "    val_count = process_dataset_split('validation', local_dataset_path, yolo_dataset_path)\n",
        "    test_count = process_dataset_split('test', local_dataset_path, yolo_dataset_path)\n",
        "\n",
        "    total_count = train_count + val_count + test_count\n",
        "    print(f\"\\nANNOTATION CONVERSION COMPLETED!\")\n",
        "    print(f\"Train: {train_count}, Validation: {val_count}, Test: {test_count}\")\n",
        "    print(f\"Total: {total_count} images\")\n",
        "\n",
        "    with open(annotations_complete_flag, 'w') as f:\n",
        "        f.write(f\"Total: {total_count} images\")\n",
        "\n",
        "# Cell 5: Create dataset configuration for YOLOv5\n",
        "dataset_config = {\n",
        "    'path': yolo_dataset_path,\n",
        "    'train': 'train/images',\n",
        "    'val': 'validation/images',\n",
        "    'test': 'test/images',\n",
        "    'nc': 1,\n",
        "    'names': ['license_plate']\n",
        "}\n",
        "\n",
        "config_path = os.path.join(yolo_dataset_path, 'dataset.yaml')\n",
        "with open(config_path, 'w') as f:\n",
        "    yaml.dump(dataset_config, f)\n",
        "\n",
        "print(\"Dataset configuration created!\")\n",
        "print(f\"Config saved at: {config_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB7QQnOOENZN",
        "outputId": "6ab5d2d1-bb6b-4174-cb20-125f50ff0232"
      },
      "outputs": [],
      "source": [
        "# Cell 6: YOLOv5m Single-Stage Training with Drive Checkpoint Backup\n",
        "import torch\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "# Make sure we're in the YOLOv5 directory\n",
        "%cd /content/yolov5\n",
        "\n",
        "# Setup paths - MODIFIED TO USE DRIVE\n",
        "model_save_dir = '/content/yolov5_models'  # Local training directory\n",
        "drive_checkpoint_dir = '/content/drive/MyDrive/yolov5_checkpoints'  # Drive backup\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(model_save_dir, exist_ok=True)\n",
        "os.makedirs(drive_checkpoint_dir, exist_ok=True)\n",
        "\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "# Check GPU memory and set conservative batch size\n",
        "if torch.cuda.is_available():\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
        "\n",
        "    if gpu_memory < 12:\n",
        "        recommended_batch = 4\n",
        "    elif gpu_memory < 16:\n",
        "        recommended_batch = 8\n",
        "    else:\n",
        "        recommended_batch = 16\n",
        "else:\n",
        "    recommended_batch = 4\n",
        "\n",
        "print(f\"Using batch size: {recommended_batch}\")\n",
        "\n",
        "# VERIFY DATASET BEFORE TRAINING\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATASET VERIFICATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Config path: {config_path}\")\n",
        "print(f\"Config exists: {os.path.exists(config_path)}\")\n",
        "\n",
        "train_imgs = os.path.join(yolo_dataset_path, 'train/images')\n",
        "val_imgs = os.path.join(yolo_dataset_path, 'validation/images')\n",
        "\n",
        "print(f\"\\nTrain images path: {train_imgs}\")\n",
        "print(f\"Train images exist: {os.path.exists(train_imgs)}\")\n",
        "if os.path.exists(train_imgs):\n",
        "    train_count = len([f for f in os.listdir(train_imgs) if f.endswith(('.jpg', '.png'))])\n",
        "    print(f\"Number of train images: {train_count}\")\n",
        "\n",
        "print(f\"\\nValidation images path: {val_imgs}\")\n",
        "print(f\"Validation images exist: {os.path.exists(val_imgs)}\")\n",
        "if os.path.exists(val_imgs):\n",
        "    val_count = len([f for f in os.listdir(val_imgs) if f.endswith(('.jpg', '.png'))])\n",
        "    print(f\"Number of validation images: {val_count}\")\n",
        "\n",
        "# Read and display dataset config\n",
        "print(\"\\nDataset Configuration:\")\n",
        "with open(config_path, 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "# CHECK FOR EXISTING CHECKPOINT - TRY DRIVE FIRST, THEN LOCAL\n",
        "drive_checkpoint_path = os.path.join(drive_checkpoint_dir, 'last.pt')\n",
        "local_checkpoint_path = os.path.join(model_save_dir, 'single_stage', 'weights', 'last.pt')\n",
        "\n",
        "resume_training = False\n",
        "checkpoint_to_use = None\n",
        "\n",
        "# Priority: Check Drive first (in case of runtime restart)\n",
        "if os.path.exists(drive_checkpoint_path):\n",
        "    print(f\"\\nâœ“ Found checkpoint in Drive: {drive_checkpoint_path}\")\n",
        "    checkpoint_to_use = drive_checkpoint_path\n",
        "    resume_training = True\n",
        "\n",
        "    # Copy to local for faster training\n",
        "    os.makedirs(os.path.dirname(local_checkpoint_path), exist_ok=True)\n",
        "    print(\"Copying checkpoint from Drive to local storage...\")\n",
        "    shutil.copy2(drive_checkpoint_path, local_checkpoint_path)\n",
        "    checkpoint_to_use = local_checkpoint_path\n",
        "    print(\"âœ“ Checkpoint copied to local storage\")\n",
        "\n",
        "elif os.path.exists(local_checkpoint_path):\n",
        "    print(f\"\\nâœ“ Found checkpoint locally: {local_checkpoint_path}\")\n",
        "    checkpoint_to_use = local_checkpoint_path\n",
        "    resume_training = True\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "if resume_training:\n",
        "    print(\"RESUMING TRAINING FROM CHECKPOINT\")\n",
        "    print(f\"Checkpoint: {checkpoint_to_use}\")\n",
        "else:\n",
        "    print(\"STARTING NEW TRAINING\")\n",
        "print(\"SINGLE-STAGE YOLOv5m TRAINING (70 epochs)\")\n",
        "print(\"Checkpoints saved every 10 epochs\")\n",
        "print(f\"Drive backup: {drive_checkpoint_dir}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Build training command with resume capability\n",
        "# IMPORTANT: When resuming, we only need the checkpoint path, not --weights\n",
        "if resume_training:\n",
        "    # YOLOv5 resume syntax: just pass the checkpoint path\n",
        "    train_cmd = f\"\"\"python -u train.py \\\n",
        "  --resume {checkpoint_to_use} \\\n",
        "  --exist-ok \\\n",
        "  --workers 4\"\"\"\n",
        "else:\n",
        "    # Fresh training with all parameters\n",
        "    train_cmd = f\"\"\"python -u train.py \\\n",
        "  --img 640 \\\n",
        "  --batch {recommended_batch} \\\n",
        "  --epochs 70 \\\n",
        "  --data {config_path} \\\n",
        "  --weights yolov5m.pt \\\n",
        "  --project {model_save_dir} \\\n",
        "  --name single_stage \\\n",
        "  --save-period 10 \\\n",
        "  --exist-ok \\\n",
        "  --workers 4\"\"\"\n",
        "\n",
        "print(\"\\nStarting YOLOv5m training...\")\n",
        "print(\"Training command:\")\n",
        "print(train_cmd)\n",
        "print(\"\\nTraining Progress:\\n\")\n",
        "\n",
        "# Run with progress bar display\n",
        "process = subprocess.Popen(\n",
        "    train_cmd,\n",
        "    shell=True,\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    universal_newlines=True,\n",
        "    bufsize=1\n",
        ")\n",
        "\n",
        "import re\n",
        "from IPython.display import clear_output\n",
        "\n",
        "current_epoch = 0\n",
        "last_progress_line = \"\"\n",
        "last_backup_epoch = -1\n",
        "\n",
        "def backup_to_drive(epoch_num):\n",
        "    \"\"\"Backup checkpoint to Drive\"\"\"\n",
        "    if os.path.exists(local_checkpoint_path):\n",
        "        try:\n",
        "            print(f\"\\nðŸ“¦ Backing up checkpoint to Drive (epoch {epoch_num})...\")\n",
        "            shutil.copy2(local_checkpoint_path, drive_checkpoint_path)\n",
        "\n",
        "            # Also backup best.pt if it exists\n",
        "            local_best = os.path.join(model_save_dir, 'single_stage', 'weights', 'best.pt')\n",
        "            drive_best = os.path.join(drive_checkpoint_dir, 'best.pt')\n",
        "            if os.path.exists(local_best):\n",
        "                shutil.copy2(local_best, drive_best)\n",
        "\n",
        "            print(f\"âœ“ Checkpoint backed up to Drive successfully at epoch {epoch_num}!\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"âš  Warning: Failed to backup to Drive: {e}\")\n",
        "            return False\n",
        "    return False\n",
        "\n",
        "for line in process.stdout:\n",
        "    # Detect epoch start\n",
        "    epoch_match = re.search(r'Epoch\\s+(\\d+)/(\\d+)', line)\n",
        "    if epoch_match:\n",
        "        current_epoch = int(epoch_match.group(1))\n",
        "        total_epochs = int(epoch_match.group(2))\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Epoch {current_epoch}/{total_epochs}\")\n",
        "        print('='*60)\n",
        "\n",
        "    # Detect epoch completion (when results are saved)\n",
        "    if 'Results saved to' in line or 'Epoch completed' in line:\n",
        "        # BACKUP TO DRIVE EVERY 5 EPOCHS (after epoch completes)\n",
        "        if current_epoch % 5 == 0 and current_epoch != last_backup_epoch and current_epoch > 0:\n",
        "            last_backup_epoch = current_epoch\n",
        "            backup_to_drive(current_epoch)\n",
        "\n",
        "    # Show progress bars\n",
        "    if any(x in line for x in ['%|', 'it/s', 's/it']) or re.search(r'\\d+/\\d+\\s*\\[', line):\n",
        "        print(f\"\\r{line.strip()[:100]}\", end='', flush=True)\n",
        "        last_progress_line = line\n",
        "\n",
        "    # Show important epoch summary lines\n",
        "    elif any(keyword in line for keyword in ['Class', 'Images', 'Instances',\n",
        "                                              'P', 'R', 'mAP50', 'mAP50-95',\n",
        "                                              'all', 'Results saved']):\n",
        "        if last_progress_line:\n",
        "            print()\n",
        "            last_progress_line = \"\"\n",
        "        print(line.rstrip())\n",
        "\n",
        "    # Show validation results\n",
        "    elif 'val:' in line.lower() or 'validating' in line.lower():\n",
        "        if last_progress_line:\n",
        "            print()\n",
        "            last_progress_line = \"\"\n",
        "        print(line.rstrip())\n",
        "\n",
        "    # Show model info and important messages\n",
        "    elif any(keyword in line for keyword in ['Model summary', 'Optimizer',\n",
        "                                              'Starting', 'hyperparameters',\n",
        "                                              'Best', 'Saving', 'Resuming']):\n",
        "        if last_progress_line:\n",
        "            print()\n",
        "            last_progress_line = \"\"\n",
        "        print(line.rstrip())\n",
        "\n",
        "print()\n",
        "\n",
        "return_code = process.wait()\n",
        "\n",
        "# FINAL BACKUP TO DRIVE\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL BACKUP TO DRIVE\")\n",
        "print(\"=\"*60)\n",
        "try:\n",
        "    weights_to_backup = [\n",
        "        ('last.pt', 'Final checkpoint'),\n",
        "        ('best.pt', 'Best model')\n",
        "    ]\n",
        "\n",
        "    for weight_file, description in weights_to_backup:\n",
        "        local_path = os.path.join(model_save_dir, 'single_stage', 'weights', weight_file)\n",
        "        drive_path = os.path.join(drive_checkpoint_dir, weight_file)\n",
        "\n",
        "        if os.path.exists(local_path):\n",
        "            shutil.copy2(local_path, drive_path)\n",
        "            size_mb = os.path.getsize(local_path) / (1024*1024)\n",
        "            print(f\"âœ“ {description} backed up: {weight_file} ({size_mb:.1f} MB)\")\n",
        "\n",
        "    # Also backup results.csv\n",
        "    results_file = os.path.join(model_save_dir, 'single_stage', 'results.csv')\n",
        "    if os.path.exists(results_file):\n",
        "        shutil.copy2(results_file, os.path.join(drive_checkpoint_dir, 'results.csv'))\n",
        "        print(\"âœ“ Training results backed up\")\n",
        "\n",
        "    print(f\"\\nâœ“ All checkpoints backed up to: {drive_checkpoint_dir}\")\n",
        "except Exception as e:\n",
        "    print(f\"âš  Warning: Failed to backup some files: {e}\")\n",
        "\n",
        "if return_code == 0:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\"*60)\n",
        "else:\n",
        "    print(f\"\\nâš  Warning: Training ended with return code {return_code}\")\n",
        "\n",
        "# Check saved models\n",
        "best_model_path = os.path.join(model_save_dir, 'single_stage', 'weights', 'best.pt')\n",
        "last_model_path = os.path.join(model_save_dir, 'single_stage', 'weights', 'last.pt')\n",
        "weights_dir = os.path.join(model_save_dir, 'single_stage', 'weights')\n",
        "\n",
        "print(\"\\nLocal Models:\")\n",
        "if os.path.exists(best_model_path):\n",
        "    print(f\"âœ“ Best model: {best_model_path}\")\n",
        "    print(f\"  Size: {os.path.getsize(best_model_path) / (1024*1024):.1f} MB\")\n",
        "\n",
        "if os.path.exists(last_model_path):\n",
        "    print(f\"âœ“ Last checkpoint: {last_model_path}\")\n",
        "    print(f\"  Size: {os.path.getsize(last_model_path) / (1024*1024):.1f} MB\")\n",
        "\n",
        "# List all epoch checkpoints\n",
        "if os.path.exists(weights_dir):\n",
        "    epoch_checkpoints = sorted([f for f in os.listdir(weights_dir) if f.startswith('epoch')])\n",
        "    if epoch_checkpoints:\n",
        "        print(f\"\\nâœ“ Periodic checkpoints ({len(epoch_checkpoints)}): {', '.join(epoch_checkpoints)}\")\n",
        "\n",
        "print(\"\\nDrive Backup:\")\n",
        "if os.path.exists(drive_checkpoint_dir):\n",
        "    drive_files = os.listdir(drive_checkpoint_dir)\n",
        "    for f in drive_files:\n",
        "        fpath = os.path.join(drive_checkpoint_dir, f)\n",
        "        size_mb = os.path.getsize(fpath) / (1024*1024)\n",
        "        print(f\"âœ“ {f} ({size_mb:.1f} MB)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"To resume training after runtime disconnection:\")\n",
        "print(\"1. Mount your Drive\")\n",
        "print(\"2. Re-run this cell - it will automatically detect and resume!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM_0yT3X8zUs",
        "outputId": "cecb5aab-a6bd-4bcc-c744-8494f79982fb"
      },
      "outputs": [],
      "source": [
        "# RUN THIS CELL MANUALLY TO BACKUP CHECKPOINTS TO DRIVE\n",
        "# You can run this while training is ongoing or after it completes\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Paths\n",
        "model_save_dir = '/content/yolov5_models'\n",
        "drive_checkpoint_dir = '/content/drive/MyDrive/yolov5_checkpoints'\n",
        "\n",
        "# Create Drive directory if it doesn't exist\n",
        "os.makedirs(drive_checkpoint_dir, exist_ok=True)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"MANUAL CHECKPOINT BACKUP TO DRIVE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Files to backup\n",
        "files_to_backup = {\n",
        "    'last.pt': 'Latest checkpoint',\n",
        "    'best.pt': 'Best model',\n",
        "    'results.csv': 'Training results'\n",
        "}\n",
        "\n",
        "# Also backup epoch checkpoints\n",
        "weights_dir = os.path.join(model_save_dir, 'single_stage', 'weights')\n",
        "if os.path.exists(weights_dir):\n",
        "    epoch_files = [f for f in os.listdir(weights_dir) if f.startswith('epoch') and f.endswith('.pt')]\n",
        "    for ef in epoch_files:\n",
        "        files_to_backup[ef] = f'Periodic checkpoint'\n",
        "\n",
        "backup_count = 0\n",
        "for filename, description in files_to_backup.items():\n",
        "    if filename == 'results.csv':\n",
        "        local_path = os.path.join(model_save_dir, 'single_stage', filename)\n",
        "    else:\n",
        "        local_path = os.path.join(model_save_dir, 'single_stage', 'weights', filename)\n",
        "\n",
        "    drive_path = os.path.join(drive_checkpoint_dir, filename)\n",
        "\n",
        "    if os.path.exists(local_path):\n",
        "        try:\n",
        "            shutil.copy2(local_path, drive_path)\n",
        "            size_mb = os.path.getsize(local_path) / (1024*1024)\n",
        "            print(f\"âœ“ {description}: {filename} ({size_mb:.1f} MB)\")\n",
        "            backup_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"âœ— Failed to backup {filename}: {e}\")\n",
        "    else:\n",
        "        print(f\"âš  Not found: {filename}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Backup complete! {backup_count} files saved to Drive\")\n",
        "print(f\"Location: {drive_checkpoint_dir}\")\n",
        "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# List all files in Drive backup location\n",
        "print(\"\\nFiles in Drive backup:\")\n",
        "if os.path.exists(drive_checkpoint_dir):\n",
        "    drive_files = sorted(os.listdir(drive_checkpoint_dir))\n",
        "    for f in drive_files:\n",
        "        fpath = os.path.join(drive_checkpoint_dir, f)\n",
        "        size_mb = os.path.getsize(fpath) / (1024*1024)\n",
        "        mtime = datetime.fromtimestamp(os.path.getmtime(fpath))\n",
        "        print(f\"  â€¢ {f} ({size_mb:.1f} MB) - {mtime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "else:\n",
        "    print(\"  No files found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twQ253oCEZ3q",
        "outputId": "c20e2792-6c8d-4b04-97ad-3c7b952f8176"
      },
      "outputs": [],
      "source": [
        "# Cell 7: YOLOv5 Evaluation\n",
        "import torch\n",
        "from models.common import DetectMultiBackend\n",
        "from utils.general import non_max_suppression, scale_boxes\n",
        "from utils.torch_utils import select_device\n",
        "\n",
        "def load_yolov5_model(weights_path):\n",
        "    \"\"\"Load YOLOv5 model\"\"\"\n",
        "    device = select_device('0' if torch.cuda.is_available() else 'cpu')\n",
        "    model = DetectMultiBackend(weights_path, device=device, dnn=False, data=config_path, fp16=False)\n",
        "    model.eval()\n",
        "    return model, device\n",
        "\n",
        "def detect_yolov5(model, device, img_path, conf_thresh=0.5, img_size=640):\n",
        "    \"\"\"Run YOLOv5 detection\"\"\"\n",
        "    from utils.dataloaders import LoadImages\n",
        "    from utils.augmentations import letterbox\n",
        "\n",
        "    # Load image\n",
        "    img = cv2.imread(img_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # Prepare input - letterbox resize like YOLOv5 does\n",
        "    img_input = letterbox(img_rgb, img_size, stride=32, auto=True)[0]\n",
        "    img_input = img_input.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_input = np.ascontiguousarray(img_input)\n",
        "    img_input = torch.from_numpy(img_input).to(device)\n",
        "    img_input = img_input.float()\n",
        "    img_input /= 255.0\n",
        "\n",
        "    if img_input.ndimension() == 3:\n",
        "        img_input = img_input.unsqueeze(0)\n",
        "\n",
        "    # Inference\n",
        "    with torch.no_grad():\n",
        "        pred = model(img_input, augment=False, visualize=False)\n",
        "\n",
        "    # NMS\n",
        "    pred = non_max_suppression(pred, conf_thresh, 0.45, classes=None, agnostic=False, max_det=1000)\n",
        "\n",
        "    # Process detections\n",
        "    boxes = []\n",
        "    if pred[0] is not None and len(pred[0]):\n",
        "        det = pred[0]\n",
        "        det[:, :4] = scale_boxes(img_input.shape[2:], det[:, :4], img.shape).round()\n",
        "\n",
        "        for *xyxy, conf, cls in det:\n",
        "            x1, y1, x2, y2 = [float(x) for x in xyxy]\n",
        "            boxes.append([x1, y1, x2, y2])\n",
        "\n",
        "    return boxes\n",
        "\n",
        "def load_ground_truth_boxes(label_path, img_width, img_height):\n",
        "    \"\"\"Load ground truth boxes from YOLO format label file\"\"\"\n",
        "    boxes = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                parts = line.split()\n",
        "                if len(parts) == 5:\n",
        "                    try:\n",
        "                        _, x_center, y_center, width, height = map(float, parts)\n",
        "\n",
        "                        x_center_abs = x_center * img_width\n",
        "                        y_center_abs = y_center * img_height\n",
        "                        width_abs = width * img_width\n",
        "                        height_abs = height * img_height\n",
        "\n",
        "                        x1 = x_center_abs - width_abs / 2\n",
        "                        y1 = y_center_abs - height_abs / 2\n",
        "                        x2 = x_center_abs + width_abs / 2\n",
        "                        y2 = y_center_abs + height_abs / 2\n",
        "\n",
        "                        boxes.append([x1, y1, x2, y2])\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "    return boxes\n",
        "\n",
        "def calculate_box_iou(box1, box2):\n",
        "    \"\"\"Calculate IoU between two bounding boxes\"\"\"\n",
        "    x1_1, y1_1, x2_1, y2_1 = box1\n",
        "    x1_2, y1_2, x2_2, y2_2 = box2\n",
        "\n",
        "    x1_i = max(x1_1, x1_2)\n",
        "    y1_i = max(y1_1, y1_2)\n",
        "    x2_i = min(x2_1, x2_2)\n",
        "    y2_i = min(y2_1, y2_2)\n",
        "\n",
        "    if x2_i <= x1_i or y2_i <= y1_i:\n",
        "        return 0.0\n",
        "\n",
        "    intersection_area = (x2_i - x1_i) * (y2_i - y1_i)\n",
        "    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "\n",
        "    if union_area == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return intersection_area / union_area\n",
        "\n",
        "def evaluate_yolov5(model, device, split_name, conf_thresh=0.5):\n",
        "    \"\"\"Comprehensive evaluation with same metrics\"\"\"\n",
        "    img_dir = f'{yolo_dataset_path}/{split_name}/images'\n",
        "    label_dir = f'{yolo_dataset_path}/{split_name}/labels'\n",
        "\n",
        "    img_files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "    tp, fp, fn, tn = 0, 0, 0, 0\n",
        "    iou_scores = []\n",
        "\n",
        "    print(f\"Evaluating {len(img_files)} images...\")\n",
        "\n",
        "    for i, img_file in enumerate(img_files):\n",
        "        if i % 500 == 0 and i > 0:\n",
        "            print(f\"Progress: {i}/{len(img_files)} ({i/len(img_files)*100:.1f}%)\")\n",
        "\n",
        "        img_path = f'{img_dir}/{img_file}'\n",
        "        label_path = f'{label_dir}/{os.path.splitext(img_file)[0]}.txt'\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        gt_boxes = load_ground_truth_boxes(label_path, w, h)\n",
        "        has_gt = len(gt_boxes) > 0\n",
        "\n",
        "        pred_boxes = detect_yolov5(model, device, img_path, conf_thresh)\n",
        "        has_pred = len(pred_boxes) > 0\n",
        "\n",
        "        if has_gt and has_pred:\n",
        "            max_iou = 0\n",
        "            for gt_box in gt_boxes:\n",
        "                for pred_box in pred_boxes:\n",
        "                    iou = calculate_box_iou(gt_box, pred_box)\n",
        "                    max_iou = max(max_iou, iou)\n",
        "\n",
        "            iou_scores.append(max_iou)\n",
        "            if max_iou > 0.5:\n",
        "                tp += 1\n",
        "            else:\n",
        "                fn += 1\n",
        "        elif has_gt and not has_pred:\n",
        "            fn += 1\n",
        "            iou_scores.append(0)\n",
        "        elif not has_gt and has_pred:\n",
        "            fp += 1\n",
        "            iou_scores.append(0)\n",
        "        else:\n",
        "            tn += 1\n",
        "            iou_scores.append(1)\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    accuracy = (tp + tn) / len(img_files)\n",
        "    avg_iou = sum(iou_scores) / len(iou_scores)\n",
        "    binary_detection = sum(1 for iou in iou_scores if iou > 0.7) / len(iou_scores)\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'accuracy': accuracy,\n",
        "        'avg_iou': avg_iou,\n",
        "        'binary_detection': binary_detection,\n",
        "        'iou_scores': iou_scores\n",
        "    }\n",
        "\n",
        "# Load the trained model\n",
        "best_model_path = os.path.join(model_save_dir, 'single_stage', 'weights', 'best.pt')\n",
        "print(f\"Loading model from: {best_model_path}\")\n",
        "trained_model, device = load_yolov5_model(best_model_path)\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\nEvaluating YOLOv5m model...\")\n",
        "val_results = evaluate_yolov5(trained_model, device, 'validation')\n",
        "test_results = evaluate_yolov5(trained_model, device, 'test')\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"YOLOv5m SINGLE-STAGE RESULTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\nVALIDATION RESULTS:\")\n",
        "print(f\"IoU: {val_results['avg_iou']:.4f}\")\n",
        "print(f\"Precision: {val_results['precision']:.4f}\")\n",
        "print(f\"Recall: {val_results['recall']:.4f}\")\n",
        "print(f\"F1-Score: {val_results['f1_score']:.4f}\")\n",
        "print(f\"Binary Detection (IoU>0.7): {val_results['binary_detection']:.4f}\")\n",
        "\n",
        "print(\"\\nTEST RESULTS:\")\n",
        "print(f\"IoU: {test_results['avg_iou']:.4f}\")\n",
        "print(f\"Precision: {test_results['precision']:.4f}\")\n",
        "print(f\"Recall: {test_results['recall']:.4f}\")\n",
        "print(f\"F1-Score: {test_results['f1_score']:.4f}\")\n",
        "print(f\"Binary Detection (IoU>0.7): {test_results['binary_detection']:.4f}\")\n",
        "print(f\"Boundary Box Accuracy: {test_results['binary_detection']*100:.1f}%\")\n",
        "\n",
        "# Cell 8: Training Visualization for YOLOv5\n",
        "results_csv = f'{model_save_dir}/single_stage/results.csv'\n",
        "\n",
        "if os.path.exists(results_csv):\n",
        "    data = pd.read_csv(results_csv)\n",
        "    # Strip whitespace from column names\n",
        "    data.columns = data.columns.str.strip()\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "    epochs = range(1, len(data) + 1)\n",
        "\n",
        "    # Box Loss - YOLOv5 column names\n",
        "    if 'train/box_loss' in data.columns:\n",
        "        axes[0,0].plot(epochs, data['train/box_loss'], 'b-', label='Train Box Loss')\n",
        "    if 'val/box_loss' in data.columns:\n",
        "        axes[0,0].plot(epochs, data['val/box_loss'], 'r-', label='Val Box Loss')\n",
        "    axes[0,0].set_title('Box Loss')\n",
        "    axes[0,0].set_xlabel('Epoch')\n",
        "    axes[0,0].set_ylabel('Loss')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True)\n",
        "\n",
        "    # mAP@0.5\n",
        "    if 'metrics/mAP_0.5' in data.columns:\n",
        "        axes[0,1].plot(epochs, data['metrics/mAP_0.5'], 'g-', label='mAP@0.5')\n",
        "        axes[0,1].set_title('mAP@0.5')\n",
        "        axes[0,1].set_xlabel('Epoch')\n",
        "        axes[0,1].set_ylabel('mAP')\n",
        "        axes[0,1].legend()\n",
        "        axes[0,1].grid(True)\n",
        "\n",
        "    # Precision & Recall\n",
        "    if 'metrics/precision' in data.columns and 'metrics/recall' in data.columns:\n",
        "        axes[1,0].plot(epochs, data['metrics/precision'], 'purple', label='Precision')\n",
        "        axes[1,0].plot(epochs, data['metrics/recall'], 'brown', label='Recall')\n",
        "        axes[1,0].set_title('Precision & Recall')\n",
        "        axes[1,0].set_xlabel('Epoch')\n",
        "        axes[1,0].set_ylabel('Score')\n",
        "        axes[1,0].legend()\n",
        "        axes[1,0].grid(True)\n",
        "\n",
        "    # Final metrics comparison\n",
        "    metrics = ['IoU', 'Precision', 'Recall', 'F1', 'Binary Det']\n",
        "    test_scores = [test_results['avg_iou'], test_results['precision'],\n",
        "                   test_results['recall'], test_results['f1_score'],\n",
        "                   test_results['binary_detection']]\n",
        "\n",
        "    axes[1,1].bar(metrics, test_scores, alpha=0.7, color=['blue', 'green', 'red', 'orange', 'purple'])\n",
        "    axes[1,1].set_title('Final Test Performance')\n",
        "    axes[1,1].set_xticklabels(metrics, rotation=45)\n",
        "    axes[1,1].set_ylim([0, 1])\n",
        "    axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{model_save_dir}/single_stage/training_metrics.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nTraining Summary:\")\n",
        "    print(f\"Total epochs: {len(data)}\")\n",
        "    if 'metrics/mAP_0.5' in data.columns:\n",
        "        print(f\"Best mAP@0.5: {data['metrics/mAP_0.5'].max():.4f}\")\n",
        "    print(f\"Final Test IoU: {test_results['avg_iou']:.4f}\")\n",
        "else:\n",
        "    print(f\"Results file not found at: {results_csv}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"YOLOv5m single-stage training completed!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gh0ajiFqcGL"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from google.colab import files, drive\n",
        "\n",
        "\n",
        "\n",
        "# Specify the folder path you want to zip\n",
        "folder_path = '/content/yolov5_models'\n",
        "zip_name = 'yolomodel'\n",
        "\n",
        "# Create a zip file of the folder\n",
        "shutil.make_archive(zip_name, 'zip', folder_path)\n",
        "\n",
        "# Save to Google Drive\n",
        "drive_path = '/content/drive/MyDrive/yolomodel.zip'\n",
        "shutil.move(f'{zip_name}.zip', drive_path)\n",
        "print(f\"Saved to Google Drive: {drive_path}\")\n",
        "\n",
        "# Also download to your local machine\n",
        "#shutil.make_archive(zip_name, 'zip', folder_path)\n",
        "#files.download(f'{zip_name}.zip')\n",
        "print(f\"Downloaded {zip_name}.zip to your computer successfully!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
