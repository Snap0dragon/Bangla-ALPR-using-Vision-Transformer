{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r_wC2R92qqg",
        "outputId": "d7571f52-c483-4fcd-c45c-73166c4f932d"
      },
      "outputs": [],
      "source": [
        "# Simple Single-Stage YOLOv8 Training for License Plate Detection\n",
        "# Run this in Google Colab\n",
        "\n",
        "# Cell 1: Install dependencies and setup\n",
        "!pip install ultralytics kaggle opencv-python matplotlib\n",
        "!pip install roboflow\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files, drive\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import pandas as pd\n",
        "\n",
        "print(\"All dependencies installed successfully!\")\n",
        "\n",
        "# Cell 2: Mount Drive and setup paths\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "local_dataset_path = '/content/Bangla_License_Plate_Dataset'\n",
        "yolo_dataset_path = '/content/yolo_dataset'\n",
        "drive_backup_path = '/content/drive/MyDrive/Bangla_License_Plate_Dataset'\n",
        "\n",
        "print(\"Drive mounted successfully!\")\n",
        "\n",
        "# Cell 3: Download and prepare dataset (same as your original)\n",
        "dataset_ready = False\n",
        "\n",
        "if os.path.exists(local_dataset_path):\n",
        "    print(\"Dataset already exists locally\")\n",
        "    dataset_ready = True\n",
        "elif os.path.exists(drive_backup_path):\n",
        "    print(\"Copying dataset from Drive to local storage...\")\n",
        "    shutil.copytree(drive_backup_path, local_dataset_path)\n",
        "    print(\"Dataset copied to local storage\")\n",
        "    dataset_ready = True\n",
        "else:\n",
        "    print(\"Dataset not found. Please upload your kaggle.json file:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "    shutil.move('kaggle.json', '/root/.kaggle/kaggle.json')\n",
        "    os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
        "\n",
        "    print(\"Downloading dataset from Kaggle...\")\n",
        "    os.system('kaggle datasets download -d nishat99/bangla-license-plate-detection -p /content')\n",
        "    os.system('unzip -q /content/bangla-license-plate-detection.zip -d /content')\n",
        "\n",
        "    if os.path.exists('/content/Bangla License Plate Dataset'):\n",
        "        shutil.move('/content/Bangla License Plate Dataset', local_dataset_path)\n",
        "        dataset_ready = True\n",
        "\n",
        "        try:\n",
        "            shutil.copytree(local_dataset_path, drive_backup_path)\n",
        "            print(\"Dataset backed up to Drive\")\n",
        "        except:\n",
        "            print(\"Drive backup failed, continuing with local dataset\")\n",
        "\n",
        "if not dataset_ready:\n",
        "    print(\"ERROR: Dataset preparation failed!\")\n",
        "else:\n",
        "    print(f\"Dataset ready at: {local_dataset_path}\")\n",
        "\n",
        "# Cell 4: Convert annotations to YOLO format (same as original)\n",
        "def mask_to_bbox(mask):\n",
        "    \"\"\"Convert binary mask to bounding box coordinates\"\"\"\n",
        "    coords = np.where(mask > 127)\n",
        "    if len(coords[0]) == 0:\n",
        "        return []\n",
        "    y_min, y_max = coords[0].min(), coords[0].max()\n",
        "    x_min, x_max = coords[1].min(), coords[1].max()\n",
        "    return [(x_min, y_min, x_max, y_max)]\n",
        "\n",
        "def bbox_to_yolo_format(bbox, img_width, img_height):\n",
        "    \"\"\"Convert bounding box to YOLO format (normalized)\"\"\"\n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "    x_center = (x_min + x_max) / 2.0\n",
        "    y_center = (y_min + y_max) / 2.0\n",
        "    width = x_max - x_min\n",
        "    height = y_max - y_min\n",
        "\n",
        "    x_center_norm = x_center / img_width\n",
        "    y_center_norm = y_center / img_height\n",
        "    width_norm = width / img_width\n",
        "    height_norm = height / img_height\n",
        "\n",
        "    return f\"0 {x_center_norm:.6f} {y_center_norm:.6f} {width_norm:.6f} {height_norm:.6f}\"\n",
        "\n",
        "def process_dataset_split(split_name, local_dataset_path, yolo_dataset_path):\n",
        "    \"\"\"Process one split with progress tracking\"\"\"\n",
        "    img_folder = os.path.join(local_dataset_path, split_name, 'img')\n",
        "    mask_folder = os.path.join(local_dataset_path, split_name, 'masks')\n",
        "\n",
        "    print(f\"\\nProcessing {split_name}:\")\n",
        "\n",
        "    if not os.path.exists(img_folder) or not os.path.exists(mask_folder):\n",
        "        print(f\"ERROR: Missing folders for {split_name}\")\n",
        "        return 0\n",
        "\n",
        "    yolo_img_dir = os.path.join(yolo_dataset_path, split_name, 'images')\n",
        "    yolo_label_dir = os.path.join(yolo_dataset_path, split_name, 'labels')\n",
        "    os.makedirs(yolo_img_dir, exist_ok=True)\n",
        "    os.makedirs(yolo_label_dir, exist_ok=True)\n",
        "\n",
        "    img_files = [f for f in os.listdir(img_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    print(f\"Found {len(img_files)} images in {split_name}\")\n",
        "\n",
        "    processed_count = 0\n",
        "\n",
        "    for i, img_file in enumerate(img_files):\n",
        "        if i % 500 == 0 and i > 0:\n",
        "            print(f\"  Processed {i}/{len(img_files)} images ({i/len(img_files)*100:.1f}%)\")\n",
        "\n",
        "        try:\n",
        "            mask_name = os.path.splitext(img_file)[0] + '.png'\n",
        "            mask_path = os.path.join(mask_folder, mask_name)\n",
        "\n",
        "            if not os.path.exists(mask_path):\n",
        "                continue\n",
        "\n",
        "            mask = cv2.imread(mask_path, 0)\n",
        "            if mask is None:\n",
        "                continue\n",
        "\n",
        "            img_path = os.path.join(img_folder, img_file)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            img_height, img_width = img.shape[:2]\n",
        "            bboxes = mask_to_bbox(mask)\n",
        "\n",
        "            # Copy image\n",
        "            dst_img_path = os.path.join(yolo_img_dir, img_file)\n",
        "            shutil.copy2(img_path, dst_img_path)\n",
        "\n",
        "            # Create label file\n",
        "            label_file = os.path.splitext(img_file)[0] + '.txt'\n",
        "            label_path = os.path.join(yolo_label_dir, label_file)\n",
        "\n",
        "            with open(label_path, 'w') as f:\n",
        "                for bbox in bboxes:\n",
        "                    yolo_line = bbox_to_yolo_format(bbox, img_width, img_height)\n",
        "                    f.write(yolo_line + '\\n')\n",
        "\n",
        "            processed_count += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_file}: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"{split_name.upper()} processed: {processed_count} images\")\n",
        "    return processed_count\n",
        "\n",
        "# Check if annotations already converted\n",
        "annotations_complete_flag = os.path.join(yolo_dataset_path, 'annotations_complete.txt')\n",
        "\n",
        "if os.path.exists(annotations_complete_flag):\n",
        "    print(\"Annotations already exist! Skipping annotation generation...\")\n",
        "else:\n",
        "    print(\"Creating YOLO annotations from masks...\")\n",
        "\n",
        "    train_count = process_dataset_split('train', local_dataset_path, yolo_dataset_path)\n",
        "    val_count = process_dataset_split('validation', local_dataset_path, yolo_dataset_path)\n",
        "    test_count = process_dataset_split('test', local_dataset_path, yolo_dataset_path)\n",
        "\n",
        "    total_count = train_count + val_count + test_count\n",
        "    print(f\"\\nANNOTATION CONVERSION COMPLETED!\")\n",
        "    print(f\"Train: {train_count}, Validation: {val_count}, Test: {test_count}\")\n",
        "    print(f\"Total: {total_count} images\")\n",
        "\n",
        "    with open(annotations_complete_flag, 'w') as f:\n",
        "        f.write(f\"Total: {total_count} images\")\n",
        "\n",
        "# Cell 5: Create dataset configuration\n",
        "dataset_config = {\n",
        "    'path': yolo_dataset_path,\n",
        "    'train': 'train/images',\n",
        "    'val': 'validation/images',\n",
        "    'test': 'test/images',\n",
        "    'nc': 1,\n",
        "    'names': ['license_plate']\n",
        "}\n",
        "\n",
        "config_path = os.path.join(yolo_dataset_path, 'dataset.yaml')\n",
        "with open(config_path, 'w') as f:\n",
        "    yaml.dump(dataset_config, f)\n",
        "\n",
        "print(\"Dataset configuration created!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9ADD7QZ2_m-",
        "outputId": "e397090e-d1e4-42d6-9c6e-57288b1eea25"
      },
      "outputs": [],
      "source": [
        "#Cell 6: Simple Single-Stage Training\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Setup paths (same as multi-stage)\n",
        "model_save_dir = '/content/yolo_models'\n",
        "os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "# Check GPU memory and recommend batch size (same logic)\n",
        "if torch.cuda.is_available():\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
        "\n",
        "    if gpu_memory < 8:\n",
        "        recommended_batch = 4\n",
        "        print(\"WARNING: Low GPU memory detected. Using batch size 4.\")\n",
        "    elif gpu_memory < 12:\n",
        "        recommended_batch = 6\n",
        "        print(\"Moderate GPU memory. Using batch size 6.\")\n",
        "    else:\n",
        "        recommended_batch = 8\n",
        "        print(\"High GPU memory. Using batch size 8.\")\n",
        "else:\n",
        "    recommended_batch = 4\n",
        "    print(\"No GPU detected. Using batch size 4.\")\n",
        "\n",
        "# Load YOLOv8m model (same as multi-stage)\n",
        "model = YOLO('yolov8m.pt')\n",
        "print(\"Loaded YOLOv8m model\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SINGLE-STAGE TRAINING (70 epochs)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Simple single-stage training with standard parameters\n",
        "results = model.train(\n",
        "    data=config_path,\n",
        "    epochs=70,  # Same total epochs as multi-stage (20+50)\n",
        "    batch=recommended_batch,\n",
        "    name='single_stage',\n",
        "    project=model_save_dir,\n",
        "    save_period=10,\n",
        "\n",
        "    # Standard YOLO hyperparameters (no advanced techniques)\n",
        "    freeze=0,           # No layer freezing\n",
        "    lr0=0.01,           # Standard learning rate (not optimized)\n",
        "    lrf=0.01,           # Standard final LR factor\n",
        "    momentum=0.937,\n",
        "    weight_decay=0.0005,\n",
        "    warmup_epochs=3,\n",
        "    warmup_momentum=0.8,\n",
        "    warmup_bias_lr=0.1,\n",
        "    box=7.5,\n",
        "    cls=0.5,\n",
        "    dfl=1.5,\n",
        "\n",
        "    # Standard augmentations (not enhanced)\n",
        "    hsv_h=0.015,\n",
        "    hsv_s=0.7,\n",
        "    hsv_v=0.4,\n",
        "    degrees=0.0,        # No rotation\n",
        "    translate=0.1,\n",
        "    scale=0.5,\n",
        "    shear=0.0,          # No shear\n",
        "    perspective=0.0,\n",
        "    flipud=0.0,\n",
        "    fliplr=0.5,\n",
        "    mosaic=1.0,\n",
        "    mixup=0.0,          # No mixup\n",
        "    copy_paste=0.0,     # No copy-paste\n",
        "\n",
        "    patience=25,\n",
        "    exist_ok=True,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"Single-stage training completed!\")\n",
        "\n",
        "# Load the trained model\n",
        "best_model_path = os.path.join(model_save_dir, 'single_stage', 'weights', 'best.pt')\n",
        "if os.path.exists(best_model_path):\n",
        "    trained_model = YOLO(best_model_path)\n",
        "    print(\"Best model loaded successfully!\")\n",
        "else:\n",
        "    print(\"Best model not found!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IO7myF2L234G",
        "outputId": "23ad68f5-8c17-489c-f8af-62c34f28862d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cell 7: Evaluation (same as your original)\n",
        "def load_ground_truth_boxes(label_path, img_width, img_height):\n",
        "    \"\"\"Load ground truth boxes from YOLO format label file\"\"\"\n",
        "    boxes = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                parts = line.split()\n",
        "                if len(parts) == 5:\n",
        "                    try:\n",
        "                        _, x_center, y_center, width, height = map(float, parts)\n",
        "\n",
        "                        x_center_abs = x_center * img_width\n",
        "                        y_center_abs = y_center * img_height\n",
        "                        width_abs = width * img_width\n",
        "                        height_abs = height * img_height\n",
        "\n",
        "                        x1 = x_center_abs - width_abs / 2\n",
        "                        y1 = y_center_abs - height_abs / 2\n",
        "                        x2 = x_center_abs + width_abs / 2\n",
        "                        y2 = y_center_abs + height_abs / 2\n",
        "\n",
        "                        boxes.append([x1, y1, x2, y2])\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "    return boxes\n",
        "\n",
        "def calculate_box_iou(box1, box2):\n",
        "    \"\"\"Calculate IoU between two bounding boxes\"\"\"\n",
        "    x1_1, y1_1, x2_1, y2_1 = box1\n",
        "    x1_2, y1_2, x2_2, y2_2 = box2\n",
        "\n",
        "    x1_i = max(x1_1, x1_2)\n",
        "    y1_i = max(y1_1, y1_2)\n",
        "    x2_i = min(x2_1, x2_2)\n",
        "    y2_i = min(y2_1, y2_2)\n",
        "\n",
        "    if x2_i <= x1_i or y2_i <= y1_i:\n",
        "        return 0.0\n",
        "\n",
        "    intersection_area = (x2_i - x1_i) * (y2_i - y1_i)\n",
        "    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "\n",
        "    if union_area == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return intersection_area / union_area\n",
        "\n",
        "def evaluate_model(model, split_name, conf_thresh=0.5):\n",
        "    \"\"\"Comprehensive evaluation with same metrics as multi-stage\"\"\"\n",
        "    img_dir = f'{yolo_dataset_path}/{split_name}/images'\n",
        "    label_dir = f'{yolo_dataset_path}/{split_name}/labels'\n",
        "\n",
        "    img_files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "    tp, fp, fn, tn = 0, 0, 0, 0\n",
        "    iou_scores = []\n",
        "\n",
        "    print(f\"Evaluating {len(img_files)} images...\")\n",
        "\n",
        "    for i, img_file in enumerate(img_files):\n",
        "        if i % 500 == 0 and i > 0:\n",
        "            print(f\"Progress: {i}/{len(img_files)}\")\n",
        "\n",
        "        img_path = f'{img_dir}/{img_file}'\n",
        "        label_path = f'{label_dir}/{os.path.splitext(img_file)[0]}.txt'\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        gt_boxes = load_ground_truth_boxes(label_path, w, h)\n",
        "        has_gt = len(gt_boxes) > 0\n",
        "\n",
        "        results = model(img_path, conf=conf_thresh, verbose=False)\n",
        "        pred_boxes = []\n",
        "        if results[0].boxes is not None:\n",
        "            for box in results[0].boxes:\n",
        "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                pred_boxes.append([x1, y1, x2, y2])\n",
        "        has_pred = len(pred_boxes) > 0\n",
        "\n",
        "        if has_gt and has_pred:\n",
        "            max_iou = 0\n",
        "            for gt_box in gt_boxes:\n",
        "                for pred_box in pred_boxes:\n",
        "                    iou = calculate_box_iou(gt_box, pred_box)\n",
        "                    max_iou = max(max_iou, iou)\n",
        "\n",
        "            iou_scores.append(max_iou)\n",
        "            if max_iou > 0.5:\n",
        "                tp += 1\n",
        "            else:\n",
        "                fn += 1\n",
        "        elif has_gt and not has_pred:\n",
        "            fn += 1\n",
        "            iou_scores.append(0)\n",
        "        elif not has_gt and has_pred:\n",
        "            fp += 1\n",
        "            iou_scores.append(0)\n",
        "        else:\n",
        "            tn += 1\n",
        "            iou_scores.append(1)\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    accuracy = (tp + tn) / len(img_files)\n",
        "    avg_iou = sum(iou_scores) / len(iou_scores)\n",
        "    binary_detection = sum(1 for iou in iou_scores if iou > 0.7) / len(iou_scores)\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'accuracy': accuracy,\n",
        "        'avg_iou': avg_iou,\n",
        "        'binary_detection': binary_detection,\n",
        "        'iou_scores': iou_scores\n",
        "    }\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Evaluating simple YOLO model...\")\n",
        "val_results = evaluate_model(trained_model, 'validation')\n",
        "test_results = evaluate_model(trained_model, 'test')\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"SIMPLE SINGLE-STAGE YOLO RESULTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\nVALIDATION RESULTS:\")\n",
        "print(f\"IoU: {val_results['avg_iou']:.4f}\")\n",
        "print(f\"Precision: {val_results['precision']:.4f}\")\n",
        "print(f\"Recall: {val_results['recall']:.4f}\")\n",
        "print(f\"F1-Score: {val_results['f1_score']:.4f}\")\n",
        "print(f\"Binary Detection (IoU>0.7): {val_results['binary_detection']:.4f}\")\n",
        "\n",
        "print(\"\\nTEST RESULTS:\")\n",
        "print(f\"IoU: {test_results['avg_iou']:.4f}\")\n",
        "print(f\"Precision: {test_results['precision']:.4f}\")\n",
        "print(f\"Recall: {test_results['recall']:.4f}\")\n",
        "print(f\"F1-Score: {test_results['f1_score']:.4f}\")\n",
        "print(f\"Binary Detection (IoU>0.7): {test_results['binary_detection']:.4f}\")\n",
        "print(f\"Boundary Box Accuracy: {test_results['binary_detection']*100:.1f}%\")\n",
        "\n",
        "# Cell 8: Training Visualization (same as multi-stage)\n",
        "results_csv = f'{model_save_dir}/single_stage/results.csv'\n",
        "\n",
        "if os.path.exists(results_csv):\n",
        "    data = pd.read_csv(results_csv)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "    epochs = range(1, len(data) + 1)\n",
        "\n",
        "    # Loss\n",
        "    axes[0,0].plot(epochs, data['train/box_loss'], 'b-', label='Train Box Loss')\n",
        "    if 'val/box_loss' in data.columns:\n",
        "        axes[0,0].plot(epochs, data['val/box_loss'], 'r-', label='Val Box Loss')\n",
        "    axes[0,0].set_title('Box Loss')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True)\n",
        "\n",
        "    # mAP\n",
        "    axes[0,1].plot(epochs, data['metrics/mAP50(B)'], 'g-', label='mAP@0.5')\n",
        "    axes[0,1].set_title('mAP@0.5')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True)\n",
        "\n",
        "    # Precision & Recall\n",
        "    axes[1,0].plot(epochs, data['metrics/precision(B)'], 'purple', label='Precision')\n",
        "    axes[1,0].plot(epochs, data['metrics/recall(B)'], 'brown', label='Recall')\n",
        "    axes[1,0].set_title('Precision & Recall')\n",
        "    axes[1,0].legend()\n",
        "    axes[1,0].grid(True)\n",
        "\n",
        "    # Final metrics comparison\n",
        "    metrics = ['IoU', 'Precision', 'Recall', 'F1', 'Binary Det']\n",
        "    test_scores = [test_results['avg_iou'], test_results['precision'],\n",
        "                   test_results['recall'], test_results['f1_score'],\n",
        "                   test_results['binary_detection']]\n",
        "\n",
        "    axes[1,1].bar(metrics, test_scores, alpha=0.7)\n",
        "    axes[1,1].set_title('Final Test Performance')\n",
        "    axes[1,1].set_xticklabels(metrics, rotation=45)\n",
        "    axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nTraining Summary:\")\n",
        "    print(f\"Total epochs: {len(data)}\")\n",
        "    print(f\"Best mAP@0.5: {data['metrics/mAP50(B)'].max():.4f}\")\n",
        "    print(f\"Final Test IoU: {test_results['avg_iou']:.4f}\")\n",
        "\n",
        "print(\"\\nSimple single-stage YOLO training completed!\")\n",
        "print(\"Now you can compare with your multi-stage results!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ewAwmOE-gIDV",
        "outputId": "7f40f8b7-4a41-4ee8-ffc1-e5f8fe3611cb"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Specify the folder path you want to zip\n",
        "folder_path = '/content/yolo_models'\n",
        "zip_name = 'yolo_models'\n",
        "\n",
        "# Create a zip file of the folder\n",
        "shutil.make_archive(zip_name, 'zip', folder_path)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(f'{zip_name}.zip')\n",
        "\n",
        "print(f\"Downloaded {zip_name}.zip successfully!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
