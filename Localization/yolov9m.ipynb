{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r_wC2R92qqg",
        "outputId": "77c12543-bc57-461b-a549-71733ac8d264"
      },
      "outputs": [],
      "source": [
        "# Simple Single-Stage YOLOv9 Training for License Plate Detection\n",
        "# Run this in Google Colab\n",
        "\n",
        "# Cell 1: Install dependencies and setup\n",
        "!pip install ultralytics kaggle opencv-python matplotlib\n",
        "!pip install roboflow\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files, drive\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import pandas as pd\n",
        "\n",
        "print(\"All dependencies installed successfully!\")\n",
        "\n",
        "# Cell 2: Mount Drive and setup paths\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "local_dataset_path = '/content/Bangla_License_Plate_Dataset'\n",
        "yolo_dataset_path = '/content/yolo_dataset'\n",
        "drive_backup_path = '/content/drive/MyDrive/Bangla_License_Plate_Dataset'\n",
        "\n",
        "print(\"Drive mounted successfully!\")\n",
        "\n",
        "# Cell 3: Download and prepare dataset (same as your original)\n",
        "dataset_ready = False\n",
        "\n",
        "if os.path.exists(local_dataset_path):\n",
        "    print(\"Dataset already exists locally\")\n",
        "    dataset_ready = True\n",
        "elif os.path.exists(drive_backup_path):\n",
        "    print(\"Copying dataset from Drive to local storage...\")\n",
        "    shutil.copytree(drive_backup_path, local_dataset_path)\n",
        "    print(\"Dataset copied to local storage\")\n",
        "    dataset_ready = True\n",
        "else:\n",
        "    print(\"Dataset not found. Please upload your kaggle.json file:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "    shutil.move('kaggle.json', '/root/.kaggle/kaggle.json')\n",
        "    os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
        "\n",
        "    print(\"Downloading dataset from Kaggle...\")\n",
        "    os.system('kaggle datasets download -d nishat99/bangla-license-plate-detection -p /content')\n",
        "    os.system('unzip -q /content/bangla-license-plate-detection.zip -d /content')\n",
        "\n",
        "    if os.path.exists('/content/Bangla License Plate Dataset'):\n",
        "        shutil.move('/content/Bangla License Plate Dataset', local_dataset_path)\n",
        "        dataset_ready = True\n",
        "\n",
        "        try:\n",
        "            shutil.copytree(local_dataset_path, drive_backup_path)\n",
        "            print(\"Dataset backed up to Drive\")\n",
        "        except:\n",
        "            print(\"Drive backup failed, continuing with local dataset\")\n",
        "\n",
        "if not dataset_ready:\n",
        "    print(\"ERROR: Dataset preparation failed!\")\n",
        "else:\n",
        "    print(f\"Dataset ready at: {local_dataset_path}\")\n",
        "\n",
        "# Cell 4: Convert annotations to YOLO format (same as original)\n",
        "def mask_to_bbox(mask):\n",
        "    \"\"\"Convert binary mask to bounding box coordinates\"\"\"\n",
        "    coords = np.where(mask > 127)\n",
        "    if len(coords[0]) == 0:\n",
        "        return []\n",
        "    y_min, y_max = coords[0].min(), coords[0].max()\n",
        "    x_min, x_max = coords[1].min(), coords[1].max()\n",
        "    return [(x_min, y_min, x_max, y_max)]\n",
        "\n",
        "def bbox_to_yolo_format(bbox, img_width, img_height):\n",
        "    \"\"\"Convert bounding box to YOLO format (normalized)\"\"\"\n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "    x_center = (x_min + x_max) / 2.0\n",
        "    y_center = (y_min + y_max) / 2.0\n",
        "    width = x_max - x_min\n",
        "    height = y_max - y_min\n",
        "\n",
        "    x_center_norm = x_center / img_width\n",
        "    y_center_norm = y_center / img_height\n",
        "    width_norm = width / img_width\n",
        "    height_norm = height / img_height\n",
        "\n",
        "    return f\"0 {x_center_norm:.6f} {y_center_norm:.6f} {width_norm:.6f} {height_norm:.6f}\"\n",
        "\n",
        "def process_dataset_split(split_name, local_dataset_path, yolo_dataset_path):\n",
        "    \"\"\"Process one split with progress tracking\"\"\"\n",
        "    img_folder = os.path.join(local_dataset_path, split_name, 'img')\n",
        "    mask_folder = os.path.join(local_dataset_path, split_name, 'masks')\n",
        "\n",
        "    print(f\"\\nProcessing {split_name}:\")\n",
        "\n",
        "    if not os.path.exists(img_folder) or not os.path.exists(mask_folder):\n",
        "        print(f\"ERROR: Missing folders for {split_name}\")\n",
        "        return 0\n",
        "\n",
        "    yolo_img_dir = os.path.join(yolo_dataset_path, split_name, 'images')\n",
        "    yolo_label_dir = os.path.join(yolo_dataset_path, split_name, 'labels')\n",
        "    os.makedirs(yolo_img_dir, exist_ok=True)\n",
        "    os.makedirs(yolo_label_dir, exist_ok=True)\n",
        "\n",
        "    img_files = [f for f in os.listdir(img_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    print(f\"Found {len(img_files)} images in {split_name}\")\n",
        "\n",
        "    processed_count = 0\n",
        "\n",
        "    for i, img_file in enumerate(img_files):\n",
        "        if i % 500 == 0 and i > 0:\n",
        "            print(f\"  Processed {i}/{len(img_files)} images ({i/len(img_files)*100:.1f}%)\")\n",
        "\n",
        "        try:\n",
        "            mask_name = os.path.splitext(img_file)[0] + '.png'\n",
        "            mask_path = os.path.join(mask_folder, mask_name)\n",
        "\n",
        "            if not os.path.exists(mask_path):\n",
        "                continue\n",
        "\n",
        "            mask = cv2.imread(mask_path, 0)\n",
        "            if mask is None:\n",
        "                continue\n",
        "\n",
        "            img_path = os.path.join(img_folder, img_file)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            img_height, img_width = img.shape[:2]\n",
        "            bboxes = mask_to_bbox(mask)\n",
        "\n",
        "            # Copy image\n",
        "            dst_img_path = os.path.join(yolo_img_dir, img_file)\n",
        "            shutil.copy2(img_path, dst_img_path)\n",
        "\n",
        "            # Create label file\n",
        "            label_file = os.path.splitext(img_file)[0] + '.txt'\n",
        "            label_path = os.path.join(yolo_label_dir, label_file)\n",
        "\n",
        "            with open(label_path, 'w') as f:\n",
        "                for bbox in bboxes:\n",
        "                    yolo_line = bbox_to_yolo_format(bbox, img_width, img_height)\n",
        "                    f.write(yolo_line + '\\n')\n",
        "\n",
        "            processed_count += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_file}: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"{split_name.upper()} processed: {processed_count} images\")\n",
        "    return processed_count\n",
        "\n",
        "# Check if annotations already converted\n",
        "annotations_complete_flag = os.path.join(yolo_dataset_path, 'annotations_complete.txt')\n",
        "\n",
        "if os.path.exists(annotations_complete_flag):\n",
        "    print(\"Annotations already exist! Skipping annotation generation...\")\n",
        "else:\n",
        "    print(\"Creating YOLO annotations from masks...\")\n",
        "\n",
        "    train_count = process_dataset_split('train', local_dataset_path, yolo_dataset_path)\n",
        "    val_count = process_dataset_split('validation', local_dataset_path, yolo_dataset_path)\n",
        "    test_count = process_dataset_split('test', local_dataset_path, yolo_dataset_path)\n",
        "\n",
        "    total_count = train_count + val_count + test_count\n",
        "    print(f\"\\nANNOTATION CONVERSION COMPLETED!\")\n",
        "    print(f\"Train: {train_count}, Validation: {val_count}, Test: {test_count}\")\n",
        "    print(f\"Total: {total_count} images\")\n",
        "\n",
        "    with open(annotations_complete_flag, 'w') as f:\n",
        "        f.write(f\"Total: {total_count} images\")\n",
        "\n",
        "# Cell 5: Create dataset configuration\n",
        "dataset_config = {\n",
        "    'path': yolo_dataset_path,\n",
        "    'train': 'train/images',\n",
        "    'val': 'validation/images',\n",
        "    'test': 'test/images',\n",
        "    'nc': 1,\n",
        "    'names': ['license_plate']\n",
        "}\n",
        "\n",
        "config_path = os.path.join(yolo_dataset_path, 'dataset.yaml')\n",
        "with open(config_path, 'w') as f:\n",
        "    yaml.dump(dataset_config, f)\n",
        "\n",
        "print(\"Dataset configuration created!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2mFfPlSo16P",
        "outputId": "c20689d3-3b27-4700-9602-797a38ce8951"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Path to your uploaded zip file\n",
        "zip_path = '/content/yolomodel.zip'\n",
        "extract_path = '/content/yolov7_models_restored'\n",
        "\n",
        "# Check if zip file exists\n",
        "if os.path.exists(zip_path):\n",
        "    print(f\"✓ Found zip file: {zip_path}\")\n",
        "    print(f\"Size: {os.path.getsize(zip_path) / (1024*1024):.1f} MB\")\n",
        "\n",
        "    # Extract the zip file\n",
        "    print(f\"\\nExtracting to: {extract_path}\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    print(\"✓ Extraction complete!\")\n",
        "\n",
        "    # Show extracted contents\n",
        "    print(\"\\nExtracted contents:\")\n",
        "    for root, dirs, files in os.walk(extract_path):\n",
        "        level = root.replace(extract_path, '').count(os.sep)\n",
        "        indent = ' ' * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        subindent = ' ' * 2 * (level + 1)\n",
        "        for file in files[:10]:  # Show first 10 files\n",
        "            print(f\"{subindent}{file}\")\n",
        "        if len(files) > 10:\n",
        "            print(f\"{subindent}... and {len(files) - 10} more files\")\n",
        "\n",
        "    # Find checkpoint files\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Looking for checkpoint files...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    checkpoint_files = []\n",
        "    for root, dirs, files in os.walk(extract_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.pt'):\n",
        "                full_path = os.path.join(root, file)\n",
        "                size_mb = os.path.getsize(full_path) / (1024*1024)\n",
        "                checkpoint_files.append((full_path, size_mb))\n",
        "                print(f\"✓ Found: {file} ({size_mb:.1f} MB)\")\n",
        "                print(f\"  Path: {full_path}\")\n",
        "\n",
        "    if checkpoint_files:\n",
        "        # Find best.pt or last.pt\n",
        "        best_pt = [f for f in checkpoint_files if 'best.pt' in f[0]]\n",
        "        last_pt = [f for f in checkpoint_files if 'last.pt' in f[0]]\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"CHECKPOINT SUMMARY\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        if best_pt:\n",
        "            print(f\"✓ best.pt found at: {best_pt[0][0]}\")\n",
        "        if last_pt:\n",
        "            print(f\"✓ last.pt found at: {last_pt[0][0]}\")\n",
        "\n",
        "        # Copy to expected location for resume\n",
        "        target_dir = '/kaggle/working/yolov7_models/yolov7_license_plate/weights'\n",
        "        os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "        if last_pt:\n",
        "            source = last_pt[0][0]\n",
        "            dest = os.path.join(target_dir, 'last.pt')\n",
        "            shutil.copy2(source, dest)\n",
        "            print(f\"\\n✓ Copied last.pt to: {dest}\")\n",
        "            print(\"You can now resume training from this checkpoint!\")\n",
        "\n",
        "        if best_pt:\n",
        "            source = best_pt[0][0]\n",
        "            dest = os.path.join(target_dir, 'best.pt')\n",
        "            shutil.copy2(source, dest)\n",
        "            print(f\"✓ Copied best.pt to: {dest}\")\n",
        "    else:\n",
        "        print(\"✗ No .pt checkpoint files found in the zip\")\n",
        "\n",
        "else:\n",
        "    print(f\"✗ Zip file not found at: {zip_path}\")\n",
        "    print(\"Please upload the file first using:\")\n",
        "    print(\"  1. Click 'Add Data' button on the right panel\")\n",
        "    print(\"  2. Or use: from google.colab import files; files.upload()\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9ADD7QZ2_m-",
        "outputId": "dfd8e28e-f639-4d8a-f5e7-51b1e3e8a53f"
      },
      "outputs": [],
      "source": [
        "#Cell 6: Single-Stage Training with Checkpoint Resume\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Setup paths\n",
        "model_save_dir = '/content/yolov7_models_restored'\n",
        "os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "# Check GPU memory and recommend batch size\n",
        "if torch.cuda.is_available():\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
        "\n",
        "    if gpu_memory < 8:\n",
        "        recommended_batch = 4\n",
        "        print(\"WARNING: Low GPU memory detected. Using batch size 4.\")\n",
        "    elif gpu_memory < 12:\n",
        "        recommended_batch = 6\n",
        "        print(\"Moderate GPU memory. Using batch size 6.\")\n",
        "    else:\n",
        "        recommended_batch = 8\n",
        "        print(\"High GPU memory. Using batch size 8.\")\n",
        "else:\n",
        "    recommended_batch = 4\n",
        "    print(\"No GPU detected. Using batch size 4.\")\n",
        "\n",
        "# Check for existing checkpoint to resume training\n",
        "checkpoint_path = os.path.join(model_save_dir, 'single_stage', 'weights', 'last.pt')\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FOUND EXISTING CHECKPOINT - RESUMING TRAINING\")\n",
        "    print(\"=\"*60)\n",
        "    model = YOLO(checkpoint_path)\n",
        "    print(f\"Loaded checkpoint from: {checkpoint_path}\")\n",
        "    resume_training = True\n",
        "else:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STARTING NEW TRAINING\")\n",
        "    print(\"=\"*60)\n",
        "    model = YOLO('yolov9m.pt')\n",
        "    print(\"Loaded fresh YOLOv9m model\")\n",
        "    resume_training = False\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SINGLE-STAGE TRAINING (70 epochs)\")\n",
        "print(\"Checkpoints saved every 10 epochs\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Training with checkpoint saving\n",
        "results = model.train(\n",
        "    data=config_path,\n",
        "    epochs=70,\n",
        "    batch=recommended_batch,\n",
        "    name='single_stage',\n",
        "    project=model_save_dir,\n",
        "    save_period=10,      # Save checkpoint every 10 epochs\n",
        "    resume=resume_training,  # Resume if checkpoint exists\n",
        "\n",
        "    # Standard YOLO hyperparameters\n",
        "    freeze=0,\n",
        "    lr0=0.01,\n",
        "    lrf=0.01,\n",
        "    momentum=0.937,\n",
        "    weight_decay=0.0005,\n",
        "    warmup_epochs=3,\n",
        "    warmup_momentum=0.8,\n",
        "    warmup_bias_lr=0.1,\n",
        "    box=7.5,\n",
        "    cls=0.5,\n",
        "    dfl=1.5,\n",
        "\n",
        "    # Standard augmentations\n",
        "    hsv_h=0.015,\n",
        "    hsv_s=0.7,\n",
        "    hsv_v=0.4,\n",
        "    degrees=0.0,\n",
        "    translate=0.1,\n",
        "    scale=0.5,\n",
        "    shear=0.0,\n",
        "    perspective=0.0,\n",
        "    flipud=0.0,\n",
        "    fliplr=0.5,\n",
        "    mosaic=1.0,\n",
        "    mixup=0.0,\n",
        "    copy_paste=0.0,\n",
        "\n",
        "    patience=25,\n",
        "    exist_ok=True,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\nTraining completed!\")\n",
        "print(f\"Checkpoints saved in: {model_save_dir}/single_stage/weights/\")\n",
        "print(\"- last.pt (latest checkpoint)\")\n",
        "print(\"- best.pt (best performing model)\")\n",
        "print(\"- epoch10.pt, epoch20.pt, etc. (periodic checkpoints)\")\n",
        "\n",
        "# Load the best trained model\n",
        "best_model_path = os.path.join(model_save_dir, 'single_stage', 'weights', 'best.pt')\n",
        "if os.path.exists(best_model_path):\n",
        "    trained_model = YOLO(best_model_path)\n",
        "    print(\"\\nBest model loaded successfully!\")\n",
        "else:\n",
        "    print(\"\\nWarning: Best model not found!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IO7myF2L234G",
        "outputId": "766ea889-3d98-4c08-c648-acddfb9ff2be"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cell 7: Evaluation (same as your original)\n",
        "def load_ground_truth_boxes(label_path, img_width, img_height):\n",
        "    \"\"\"Load ground truth boxes from YOLO format label file\"\"\"\n",
        "    boxes = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                parts = line.split()\n",
        "                if len(parts) == 5:\n",
        "                    try:\n",
        "                        _, x_center, y_center, width, height = map(float, parts)\n",
        "\n",
        "                        x_center_abs = x_center * img_width\n",
        "                        y_center_abs = y_center * img_height\n",
        "                        width_abs = width * img_width\n",
        "                        height_abs = height * img_height\n",
        "\n",
        "                        x1 = x_center_abs - width_abs / 2\n",
        "                        y1 = y_center_abs - height_abs / 2\n",
        "                        x2 = x_center_abs + width_abs / 2\n",
        "                        y2 = y_center_abs + height_abs / 2\n",
        "\n",
        "                        boxes.append([x1, y1, x2, y2])\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "    return boxes\n",
        "\n",
        "def calculate_box_iou(box1, box2):\n",
        "    \"\"\"Calculate IoU between two bounding boxes\"\"\"\n",
        "    x1_1, y1_1, x2_1, y2_1 = box1\n",
        "    x1_2, y1_2, x2_2, y2_2 = box2\n",
        "\n",
        "    x1_i = max(x1_1, x1_2)\n",
        "    y1_i = max(y1_1, y1_2)\n",
        "    x2_i = min(x2_1, x2_2)\n",
        "    y2_i = min(y2_1, y2_2)\n",
        "\n",
        "    if x2_i <= x1_i or y2_i <= y1_i:\n",
        "        return 0.0\n",
        "\n",
        "    intersection_area = (x2_i - x1_i) * (y2_i - y1_i)\n",
        "    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "\n",
        "    if union_area == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return intersection_area / union_area\n",
        "\n",
        "def evaluate_model(model, split_name, conf_thresh=0.5):\n",
        "    \"\"\"Comprehensive evaluation with same metrics as multi-stage\"\"\"\n",
        "    img_dir = f'{yolo_dataset_path}/{split_name}/images'\n",
        "    label_dir = f'{yolo_dataset_path}/{split_name}/labels'\n",
        "\n",
        "    img_files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "    tp, fp, fn, tn = 0, 0, 0, 0\n",
        "    iou_scores = []\n",
        "\n",
        "    print(f\"Evaluating {len(img_files)} images...\")\n",
        "\n",
        "    for i, img_file in enumerate(img_files):\n",
        "        if i % 500 == 0 and i > 0:\n",
        "            print(f\"Progress: {i}/{len(img_files)}\")\n",
        "\n",
        "        img_path = f'{img_dir}/{img_file}'\n",
        "        label_path = f'{label_dir}/{os.path.splitext(img_file)[0]}.txt'\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        gt_boxes = load_ground_truth_boxes(label_path, w, h)\n",
        "        has_gt = len(gt_boxes) > 0\n",
        "\n",
        "        results = model(img_path, conf=conf_thresh, verbose=False)\n",
        "        pred_boxes = []\n",
        "        if results[0].boxes is not None:\n",
        "            for box in results[0].boxes:\n",
        "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                pred_boxes.append([x1, y1, x2, y2])\n",
        "        has_pred = len(pred_boxes) > 0\n",
        "\n",
        "        if has_gt and has_pred:\n",
        "            max_iou = 0\n",
        "            for gt_box in gt_boxes:\n",
        "                for pred_box in pred_boxes:\n",
        "                    iou = calculate_box_iou(gt_box, pred_box)\n",
        "                    max_iou = max(max_iou, iou)\n",
        "\n",
        "            iou_scores.append(max_iou)\n",
        "            if max_iou > 0.5:\n",
        "                tp += 1\n",
        "            else:\n",
        "                fn += 1\n",
        "        elif has_gt and not has_pred:\n",
        "            fn += 1\n",
        "            iou_scores.append(0)\n",
        "        elif not has_gt and has_pred:\n",
        "            fp += 1\n",
        "            iou_scores.append(0)\n",
        "        else:\n",
        "            tn += 1\n",
        "            iou_scores.append(1)\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    accuracy = (tp + tn) / len(img_files)\n",
        "    avg_iou = sum(iou_scores) / len(iou_scores)\n",
        "    binary_detection = sum(1 for iou in iou_scores if iou > 0.7) / len(iou_scores)\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'accuracy': accuracy,\n",
        "        'avg_iou': avg_iou,\n",
        "        'binary_detection': binary_detection,\n",
        "        'iou_scores': iou_scores\n",
        "    }\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Evaluating simple YOLO model...\")\n",
        "val_results = evaluate_model(trained_model, 'validation')\n",
        "test_results = evaluate_model(trained_model, 'test')\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"SIMPLE SINGLE-STAGE YOLO RESULTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\nVALIDATION RESULTS:\")\n",
        "print(f\"IoU: {val_results['avg_iou']:.4f}\")\n",
        "print(f\"Precision: {val_results['precision']:.4f}\")\n",
        "print(f\"Recall: {val_results['recall']:.4f}\")\n",
        "print(f\"F1-Score: {val_results['f1_score']:.4f}\")\n",
        "print(f\"Binary Detection (IoU>0.7): {val_results['binary_detection']:.4f}\")\n",
        "\n",
        "print(\"\\nTEST RESULTS:\")\n",
        "print(f\"IoU: {test_results['avg_iou']:.4f}\")\n",
        "print(f\"Precision: {test_results['precision']:.4f}\")\n",
        "print(f\"Recall: {test_results['recall']:.4f}\")\n",
        "print(f\"F1-Score: {test_results['f1_score']:.4f}\")\n",
        "print(f\"Binary Detection (IoU>0.7): {test_results['binary_detection']:.4f}\")\n",
        "print(f\"Boundary Box Accuracy: {test_results['binary_detection']*100:.1f}%\")\n",
        "\n",
        "# Cell 8: Training Visualization (same as multi-stage)\n",
        "results_csv = f'{model_save_dir}/single_stage/results.csv'\n",
        "\n",
        "if os.path.exists(results_csv):\n",
        "    data = pd.read_csv(results_csv)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "    epochs = range(1, len(data) + 1)\n",
        "\n",
        "    # Loss\n",
        "    axes[0,0].plot(epochs, data['train/box_loss'], 'b-', label='Train Box Loss')\n",
        "    if 'val/box_loss' in data.columns:\n",
        "        axes[0,0].plot(epochs, data['val/box_loss'], 'r-', label='Val Box Loss')\n",
        "    axes[0,0].set_title('Box Loss')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True)\n",
        "\n",
        "    # mAP\n",
        "    axes[0,1].plot(epochs, data['metrics/mAP50(B)'], 'g-', label='mAP@0.5')\n",
        "    axes[0,1].set_title('mAP@0.5')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True)\n",
        "\n",
        "    # Precision & Recall\n",
        "    axes[1,0].plot(epochs, data['metrics/precision(B)'], 'purple', label='Precision')\n",
        "    axes[1,0].plot(epochs, data['metrics/recall(B)'], 'brown', label='Recall')\n",
        "    axes[1,0].set_title('Precision & Recall')\n",
        "    axes[1,0].legend()\n",
        "    axes[1,0].grid(True)\n",
        "\n",
        "    # Final metrics comparison\n",
        "    metrics = ['IoU', 'Precision', 'Recall', 'F1', 'Binary Det']\n",
        "    test_scores = [test_results['avg_iou'], test_results['precision'],\n",
        "                   test_results['recall'], test_results['f1_score'],\n",
        "                   test_results['binary_detection']]\n",
        "\n",
        "    axes[1,1].bar(metrics, test_scores, alpha=0.7)\n",
        "    axes[1,1].set_title('Final Test Performance')\n",
        "    axes[1,1].set_xticklabels(metrics, rotation=45)\n",
        "    axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nTraining Summary:\")\n",
        "    print(f\"Total epochs: {len(data)}\")\n",
        "    print(f\"Best mAP@0.5: {data['metrics/mAP50(B)'].max():.4f}\")\n",
        "    print(f\"Final Test IoU: {test_results['avg_iou']:.4f}\")\n",
        "\n",
        "print(\"\\nSimple single-stage YOLO training completed!\")\n",
        "print(\"Now you can compare with your multi-stage results!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pva6KiahTCj"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from google.colab import files, drive\n",
        "\n",
        "\n",
        "\n",
        "# Specify the folder path you want to zip\n",
        "folder_path = '/content/yolov7_models_restored'\n",
        "zip_name = 'yolomodel2'\n",
        "\n",
        "# Create a zip file of the folder\n",
        "shutil.make_archive(zip_name, 'zip', folder_path)\n",
        "\n",
        "# Save to Google Drive\n",
        "drive_path = '/content/drive/MyDrive/yolomodel2.zip'\n",
        "shutil.move(f'{zip_name}.zip', drive_path)\n",
        "print(f\"Saved to Google Drive: {drive_path}\")\n",
        "\n",
        "# Also download to your local machine\n",
        "#shutil.make_archive(zip_name, 'zip', folder_path)\n",
        "#files.download(f'{zip_name}.zip')\n",
        "print(f\"Downloaded {zip_name}.zip to your computer successfully!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
